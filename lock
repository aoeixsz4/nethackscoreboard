cfg/nethack_def.txt:Defines mapping from role three-letter code (such as arc, ran or wiz) to proper role name (all lowercase). This mapping should contain all roles of all variants.
cfg/nethack_def.txt:Defines mapping from race three-letter code (such as hum, dwa etc) to proper race name (all lowercase). This mapping should contain all races of all variants.
cfg/nethack_def.txt:Defines mapping fro alignment three-letter code (law, neu and cha) to proper alignment name (all lowercase). This mapping should contain all possible alignments.
cfg/nethack_def.txt:This defines default conducts as decimal number to four-letter conduct code.
cfg/nethack_def.txt:Defines mapping from variant short-codes (nh, nh4, ace etc.) to full names (properly capitalized).
cfg/nethack_def.txt:roles   - list of roles
cfg/nethack_def.txt:races   - list of races
cfg/nethack_def.txt:conduct - optional variant specific bitmap of conducts
cfg/nhdb_def.json:  #--- HTML files are generated in this place
cfg/nhdb_def.json:  #--- database session configuration
cfg/nhdb_def.json:  #--- authentication info for database sessions is stored in this file
cfg/nhdb_def.json:  #--- define wget command-line options
cfg/nhdb_def.json:  "wget" : "wget --connect-timeout=10 --dns-timeout=5 --read-timeout=60 -t 1 -c -q -O %s %s",
cfg/nhdb_def.json:  #--- feeder configuration
cfg/nhdb_def.json:  #--- following fields must be present in the xlogfile or the line is rejected
cfg/nhdb_def.json:  #--- regular xlogfile fields; do not change unless you know what you're doing
cfg/nhdb_def.json:  #--- xlogfile lines with following names are dropped
cfg/nhdb_def.json:  #--- path to local xlogfile copies
cfg/nhdb_def.json:  #--- variants to include in the First To Ascend page
cfg/nethack_def.json:# required facts about NetHack and its variants supported by the NetHack Score-
cfg/nethack_def.json:  #--- define all roles
cfg/nethack_def.json:  #--- define all races
cfg/nethack_def.json:    "hlf" : "half-dragon",
cfg/nethack_def.json:    "swn" : "yuki-onna",
cfg/nethack_def.json:  #--- define all alignments
cfg/nethack_def.json:    "non" : "non-aligned"
cfg/nethack_def.json:  #--- define all genders
cfg/nethack_def.json:  #--- ordered list of all conducts
cfg/nethack_def.json:  #--- ordered list of variants
cfg/nethack_def.json:  #--- define roles/races/alingments/genders and conducts for a variant
cfg/nethack_def.json:  #--- "rules" define available player character combinations by using
cfg/nethack_def.json:  #--- rulesets; note, that this is one of the two ways to define the
cfg/nethack_def.json:  #--- information, the other being "nh_combo_list_def"
cfg/nethack_def.json:  #---
cfg/nethack_def.json:  #--- the general format of each rule-line is following:
cfg/nethack_def.json:  #---    [ trigger, require1, require2, ..., requireN ]
cfg/nethack_def.json:  #---
cfg/nethack_def.json:  #--- "trigger" can be a single value or multiple values as an array
cfg/nethack_def.json:  #---
cfg/nethack_def.json:  #--- both triggers and requires are three-letter string prepended with
cfg/nethack_def.json:  #--- special character: $ role, % race, # alignment and ! gender
cfg/nethack_def.json:  #---
cfg/nethack_def.json:  #--- once the trigger(s) match(es), the requirements must be satisfied;
cfg/nethack_def.json:  #--- if the requirements are not satisfied, the combo is rejected and
cfg/nethack_def.json:  #--- no further matching is attempted; if the requirements are met,
cfg/nethack_def.json:  #--- matching continues with next rule;
cfg/nethack_def.json:  #---
cfg/nethack_def.json:  #--- the requirements match so that for given race/gender/alignment the
cfg/nethack_def.json:  #--- results are ORed, but between them, the matches are ANDed.
cfg/nhdb_def.json.example:  #--- HTML files are generated in this place
cfg/nhdb_def.json.example:  #--- database session configuration
cfg/nhdb_def.json.example:  #--- authentication info for database sessions is stored in this file
cfg/nhdb_def.json.example:  #--- define wget command-line options
cfg/nhdb_def.json.example:  "wget" : "wget --connect-timeout=10 --dns-timeout=5 --read-timeout=60 -t 1 -c -q -O %s %s",
cfg/nhdb_def.json.example:  #--- feeder configuration
cfg/nhdb_def.json.example:  #--- following fields must be present in the xlogfile or the line is rejected
cfg/nhdb_def.json.example:  #--- regular xlogfile fields; do not change unless you know what you're doing
cfg/nhdb_def.json.example:  #--- xlogfile lines with following names are dropped
cfg/nhdb_def.json.example:  #--- path to local xlogfile copies
cfg/nhdb_def.json.example:  #--- variants to include in the First To Ascend page
js/tabsort.js:      return $(cell).attr('data-sortkey');
js/tabsort.js:  // "data-sorter" equal to "true" or "custkey"
.gitignore:nhdb.sublime-project
.gitignore:nhdb.sublime-workspace
.gitignore:schema/nhdb-users.txt
.gitignore:TO-DO
.gitignore:schema/db-reset.sql
.gitignore:nhdb.sublime-project-nms1
.git/info/exclude:# git ls-files --others --exclude-from=.git/info/exclude
.git/config:	url = git@github.com:aoeixsz4/nhs-fork.git
.git/packed-refs:# pack-refs with: peeled fully-peeled sorted 
Binary file .git/objects/85/87b04b246b11b4cc1f01ce50b5c78ff8f4127b matches
Binary file .git/objects/81/02902eb115ee3b70744722aedab1b9e258493f matches
Binary file .git/objects/45/d5d17e86f1ab171d4a7c49224cb1a07ae99654 matches
Binary file .git/objects/32/f54f13d77e7aa8f7675523b5f486d09fb697c8 matches
Binary file .git/objects/4a/a1453e01bb7ae16d481909816b06a9d771fdd2 matches
Binary file .git/objects/00/1c07e5cf51340cdd0256ecf726a8842da345f5 matches
Binary file .git/objects/pack/pack-0da213006b1ff641124cd1de00e1e2fa64711571.idx matches
Binary file .git/objects/pack/pack-0da213006b1ff641124cd1de00e1e2fa64711571.pack matches
Binary file .git/objects/27/2021947cf9f2f11babc78bfca09e6bd2630a1c matches
Binary file .git/index matches
.git/hooks/post-update.sample:# To enable this hook, rename this file to "post-update".
.git/hooks/post-update.sample:exec git update-server-info
.git/hooks/pre-commit.sample:# exit with non-zero status after issuing an appropriate message if
.git/hooks/pre-commit.sample:# To enable this hook, rename this file to "pre-commit".
.git/hooks/pre-commit.sample:if git rev-parse --verify HEAD >/dev/null 2>&1
.git/hooks/pre-commit.sample:	against=$(git hash-object -t tree /dev/null)
.git/hooks/pre-commit.sample:# If you want to allow non-ASCII filenames set this variable to true.
.git/hooks/pre-commit.sample:allownonascii=$(git config --type=bool hooks.allownonascii)
.git/hooks/pre-commit.sample:# Cross platform projects tend to avoid non-ASCII filenames; prevent
.git/hooks/pre-commit.sample:	test $(git diff --cached --name-only --diff-filter=A -z $against |
.git/hooks/pre-commit.sample:	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
.git/hooks/pre-commit.sample:Error: Attempt to add a non-ASCII file name.
.git/hooks/pre-commit.sample:exec git diff-index --check --cached $against --
.git/hooks/commit-msg.sample:# that has the commit message.  The hook should exit with non-zero
.git/hooks/commit-msg.sample:# To enable this hook, rename this file to "commit-msg".
.git/hooks/commit-msg.sample:# Uncomment the below to add a Signed-off-by line to the message.
.git/hooks/commit-msg.sample:# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
.git/hooks/commit-msg.sample:# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
.git/hooks/commit-msg.sample:# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"
.git/hooks/commit-msg.sample:# This example catches duplicate Signed-off-by lines.
.git/hooks/commit-msg.sample:test "" = "$(grep '^Signed-off-by: ' "$1" |
.git/hooks/commit-msg.sample:	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
.git/hooks/commit-msg.sample:	echo >&2 Duplicate Signed-off-by lines.
.git/hooks/update.sample:# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
.git/hooks/update.sample:# ------
.git/hooks/update.sample:# --- Command line
.git/hooks/update.sample:# --- Safety check
.git/hooks/update.sample:if [ -z "$GIT_DIR" ]; then
.git/hooks/update.sample:if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
.git/hooks/update.sample:# --- Config
.git/hooks/update.sample:allowunannotated=$(git config --type=bool hooks.allowunannotated)
.git/hooks/update.sample:allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
.git/hooks/update.sample:denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
.git/hooks/update.sample:allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
.git/hooks/update.sample:allowmodifytag=$(git config --type=bool hooks.allowmodifytag)
.git/hooks/update.sample:projectdesc=$(sed -e '1q' "$GIT_DIR/description")
.git/hooks/update.sample:# --- Check types
.git/hooks/update.sample:	newrev_type=$(git cat-file -t $newrev)
.git/hooks/update.sample:		# un-annotated tag
.git/hooks/update.sample:			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
.git/hooks/update.sample:			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
.git/hooks/update.sample:		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
.git/hooks/update.sample:		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
.git/hooks/update.sample:# --- Finished
.git/hooks/pre-applypatch.sample:# by applypatch from an e-mail message.
.git/hooks/pre-applypatch.sample:# The hook should exit with non-zero status after issuing an
.git/hooks/pre-applypatch.sample:# To enable this hook, rename this file to "pre-applypatch".
.git/hooks/pre-applypatch.sample:. git-sh-setup
.git/hooks/pre-applypatch.sample:precommit="$(git rev-parse --git-path hooks/pre-commit)"
.git/hooks/pre-applypatch.sample:test -x "$precommit" && exec "$precommit" ${1+"$@"}
.git/hooks/fsmonitor-watchman.sample:# To enable this hook, rename this file to "query-watchman" and set
.git/hooks/fsmonitor-watchman.sample:# 'git config core.fsmonitor .git/hooks/query-watchman'
.git/hooks/fsmonitor-watchman.sample:	die "Unsupported query-fsmonitor hook version '$version'.\n" .
.git/hooks/fsmonitor-watchman.sample:		output_result($o->{clock}, @{$o->{files}});
.git/hooks/fsmonitor-watchman.sample:	# open (my $fh, ">", ".git/watchman-output.out");
.git/hooks/fsmonitor-watchman.sample:	return $json_pkg->new->utf8->decode($response);
.git/hooks/fsmonitor-watchman.sample:	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
.git/hooks/fsmonitor-watchman.sample:	# open (my $fh, ">", ".git/watchman-query.json");
.git/hooks/fsmonitor-watchman.sample:	# open ($fh, ">", ".git/watchman-response.json");
.git/hooks/fsmonitor-watchman.sample:	return $json_pkg->new->utf8->decode($response);
.git/hooks/fsmonitor-watchman.sample:	my $error = $output->{error};
.git/hooks/fsmonitor-watchman.sample:		$retry--;
.git/hooks/fsmonitor-watchman.sample:		$output = $json_pkg->new->utf8->decode($response);
.git/hooks/fsmonitor-watchman.sample:		$error = $output->{error};
.git/hooks/fsmonitor-watchman.sample:		# open (my $fh, ">", ".git/watchman-output.out");
.git/hooks/fsmonitor-watchman.sample:		$error = $output->{error};
.git/hooks/fsmonitor-watchman.sample:		output_result($o->{clock}, ("/"));
.git/hooks/fsmonitor-watchman.sample:		$last_update_token = $o->{clock};
.git/hooks/pre-push.sample:# pushed.  If this script exits with a non-zero status nothing will be pushed.
.git/hooks/pre-push.sample:# $1 -- Name of the remote to which the push is being done
.git/hooks/pre-push.sample:# $2 -- URL to which the push is being done
.git/hooks/pre-push.sample:		commit=`git rev-list -n 1 --grep '^WIP' "$range"`
.git/hooks/pre-push.sample:		if [ -n "$commit" ]
.git/hooks/prepare-commit-msg.sample:# message file.  If the hook fails with a non-zero status,
.git/hooks/prepare-commit-msg.sample:# To enable this hook, rename this file to "prepare-commit-msg".
.git/hooks/prepare-commit-msg.sample:# The second includes the output of "git diff --name-status -r"
.git/hooks/prepare-commit-msg.sample:# commented because it doesn't cope with --amend or with squashed
.git/hooks/prepare-commit-msg.sample:# The third example adds a Signed-off-by line to the message, that can
.git/hooks/prepare-commit-msg.sample:/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"
.git/hooks/prepare-commit-msg.sample:#    /usr/bin/perl -i.bak -pe '
.git/hooks/prepare-commit-msg.sample:#       print "\n" . `git diff --cached --name-status -r`
.git/hooks/prepare-commit-msg.sample:# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
.git/hooks/prepare-commit-msg.sample:# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
.git/hooks/prepare-commit-msg.sample:# if test -z "$COMMIT_SOURCE"
.git/hooks/prepare-commit-msg.sample:#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
.git/hooks/pre-merge-commit.sample:# exit with non-zero status after issuing an appropriate message to
.git/hooks/pre-merge-commit.sample:# To enable this hook, rename this file to "pre-merge-commit".
.git/hooks/pre-merge-commit.sample:. git-sh-setup
.git/hooks/pre-merge-commit.sample:test -x "$GIT_DIR/hooks/pre-commit" &&
.git/hooks/pre-merge-commit.sample:        exec "$GIT_DIR/hooks/pre-commit"
.git/hooks/pre-rebase.sample:# The "pre-rebase" hook is run just before "git rebase" starts doing
.git/hooks/pre-rebase.sample:# non-zero status.
.git/hooks/pre-rebase.sample:# $1 -- the upstream the series was forked from.
.git/hooks/pre-rebase.sample:# $2 -- the branch being rebased (or empty when rebasing the current branch).
.git/hooks/pre-rebase.sample:	topic=`git symbolic-ref HEAD` ||
.git/hooks/pre-rebase.sample:git show-ref -q "$topic" || {
.git/hooks/pre-rebase.sample:not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
.git/hooks/pre-rebase.sample:if test -z "$not_in_master"
.git/hooks/pre-rebase.sample:only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
.git/hooks/pre-rebase.sample:only_next_2=`git rev-list ^master           ${publish} | sort`
.git/hooks/pre-rebase.sample:	not_in_topic=`git rev-list "^$topic" master`
.git/hooks/pre-rebase.sample:	if test -z "$not_in_topic"
.git/hooks/pre-rebase.sample:	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
.git/hooks/pre-rebase.sample:	/usr/bin/perl -e '
.git/hooks/pre-rebase.sample:			/^([0-9a-f]+) /;
.git/hooks/pre-rebase.sample:				/^([0-9a-f]+) (.*)$/;
.git/hooks/pre-rebase.sample:			if (!exists $not_in_next{$elem->[0]}) {
.git/hooks/pre-rebase.sample:				print STDERR " $elem->[1]\n";
.git/hooks/pre-rebase.sample:    build on top of it -- other people may already want to
.git/hooks/pre-rebase.sample:		   o---o---o---o---o---o---o---o---o---o "next"
.git/hooks/pre-rebase.sample:		 /   a---a---b A     /           /
.git/hooks/pre-rebase.sample:	       /   /   c---c---c---c B         /
.git/hooks/pre-rebase.sample:	     /   /   /   b---b C     \       /
.git/hooks/pre-rebase.sample:    ---o---o---o---o---o---o---o---o---o---o---o "master"
.git/hooks/pre-rebase.sample:	git rev-list ^master ^topic next
.git/hooks/pre-rebase.sample:	git rev-list ^master        next
.git/hooks/pre-rebase.sample:	git rev-list master..topic
.git/hooks/pre-receive.sample:# To enable this hook, rename this file to "pre-receive".
.git/hooks/pre-receive.sample:if test -n "$GIT_PUSH_OPTION_COUNT"
.git/hooks/pre-receive.sample:	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
.git/hooks/pre-receive.sample:			echo "echo from the pre-receive-hook: ${value#*=}" >&2
.git/hooks/applypatch-msg.sample:# applypatch from an e-mail message.
.git/hooks/applypatch-msg.sample:# The hook should exit with non-zero status after issuing an
.git/hooks/applypatch-msg.sample:# To enable this hook, rename this file to "applypatch-msg".
.git/hooks/applypatch-msg.sample:. git-sh-setup
.git/hooks/applypatch-msg.sample:commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
.git/hooks/applypatch-msg.sample:test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
lib/NetHack/Config.pm:# access the configuration data. Note, that variant-specific info uses the
lib/NetHack/Config.pm:  if(-r $self->config_file()) {
lib/NetHack/Config.pm:    my $js = new JSON->relaxed(1);
lib/NetHack/Config.pm:    open(my $fh, '<', $self->config_file());
lib/NetHack/Config.pm:    my $cfg = $js->decode($def_json) or die 'Cannot parse NetHack.pm configuration';
lib/NetHack/Config.pm:    die 'Cannot read config file ' . $self->config_file();
lib/NetHack/Config.pm:  return @{$self->config()->{'nh_variants_ord'}};
lib/NetHack/Config.pm:  foreach my $variant ($self->variants()) {
lib/NetHack/Config.pm:    $variants{$variant} = $self->config()->{'nh_variants'}{$variant}{'name'};
lib/NetHack/Config.pm:  return @{$self->config()->{'nh_conduct_ord'}};
lib/NetHack/Variant.pm:# variant-specific queries.
lib/NetHack/Variant.pm:  my $vc = $self->_def();
lib/NetHack/Variant.pm:  my $gc = $self->config()->config();
lib/NetHack/Variant.pm:  if(exists $vc->{$category} || $category eq 'achieve') {
lib/NetHack/Variant.pm:    return $vc->{$category};
lib/NetHack/Variant.pm:  } elsif(exists $gc->{'nh_variants'}{'nh'}{$category}) {
lib/NetHack/Variant.pm:    return $gc->{'nh_variants'}{'nh'}{$category}
lib/NetHack/Variant.pm:      $self->variant()
lib/NetHack/Variant.pm:  my $vc = $self->_def();
lib/NetHack/Variant.pm:  my $gc = $self->config()->config();
lib/NetHack/Variant.pm:  if(exists $vc->{$category}) {
lib/NetHack/Variant.pm:    return $vc->{$category};
lib/NetHack/Variant.pm:  } elsif(exists $vc->{$other}) {
lib/NetHack/Variant.pm:  } elsif(exists $gc->{'nh_variants'}{'nh'}{$category}) {
lib/NetHack/Variant.pm:    return $gc->{'nh_variants'}{'nh'}{$category};
lib/NetHack/Variant.pm:  my $c = $self->config()->config();
lib/NetHack/Variant.pm:  return $c->{'nh_variants'}{ $self->variant() };
lib/NetHack/Variant.pm:  #--- get reverse code-to-value mapping for conducts
lib/NetHack/Variant.pm:  my %con_to_val = reverse %{$self->conducts()};
lib/NetHack/Variant.pm:  my %ach_to_val = reverse %{$self->achievements() // {}};
lib/NetHack/Variant.pm:  #--- get ordered list of conducts
lib/NetHack/Variant.pm:  for my $c ($self->config()->list_conducts_ordered()) {
lib/NetHack/Variant.pm:  #--- return depending on context
lib/NetHack/Variant.pm:    !$self->roles()
lib/NetHack/Variant.pm:    || !$self->races()
lib/NetHack/Variant.pm:    || !$self->genders()
lib/NetHack/Variant.pm:    || !$self->alignments()
lib/NetHack/Variant.pm:#    |<--- trigger rule(s) ------------>|<--- enforce rules ----->|
lib/NetHack/Variant.pm:  #--- arguments (in lowercase)
lib/NetHack/Variant.pm:  #--- if not rules exist, return undef
lib/NetHack/Variant.pm:  return undef if !defined $self->rules();
lib/NetHack/Variant.pm:  #--- iterate over all rules (start)
lib/NetHack/Variant.pm:  foreach my $rule (@{$self->rules()}) {
lib/NetHack/Variant.pm:  #--- trigger rules
lib/NetHack/Variant.pm:    my $trigger_set = ref($rule->[0]) ? $rule->[0] : [ $rule->[0] ];
lib/NetHack/Variant.pm:  #--- enforce rules
lib/NetHack/Variant.pm:    my @enforce_rules = @{$rule}[1 .. (scalar(@$rule)-1) ];
lib/NetHack/Variant.pm:  #--- iterate over all rules (end)
lib/NetHack/Variant.pm:  #--- finish successfully
lib/NetHack/Variant.pm:  #--- arguments (in lowercase)
lib/NetHack/Variant.pm:  #--- return false if no list def exists for given variant
lib/NetHack/Variant.pm:  return undef if !defined $self->enum();
lib/NetHack/Variant.pm:  #--- search the list
lib/NetHack/Variant.pm:      lc($_->[0]) eq $role
lib/NetHack/Variant.pm:      && lc($_->[1]) eq $race
lib/NetHack/Variant.pm:      && lc($_->[2]) eq $gender
lib/NetHack/Variant.pm:      && lc($_->[3]) eq $alignment
lib/NetHack/Variant.pm:    } @{$self->enum()}
lib/NetHack/Variant.pm:  #--- if the given variant does not all of the allowable character
lib/NetHack/Variant.pm:  #--- categories defined, then we do not perform combo validity check at
lib/NetHack/Variant.pm:  #--- all and just return true
lib/NetHack/Variant.pm:  return 1 if !$self->combo_defined();
lib/NetHack/Variant.pm:  #--- combine the two validation methods
lib/NetHack/Variant.pm:  return $self->combo_valid_by_enum(@_) || $self->combo_valid_by_rules(@_);
lib/NetHack/Variant.pm:# Function to initialize table of role-race-alignment combos (gender is left
lib/NetHack/Variant.pm:# - table -- contains three dimensional array reference
lib/NetHack/Variant.pm:# - idx -- contains hash ref with {role}{race}{align} index to above table;
lib/NetHack/Variant.pm:#          the index is understood as triplet of indexes into the 3-d array
lib/NetHack/Variant.pm:  #--- arguments
lib/NetHack/Variant.pm:  #--- do nothing for variants with undefined rules/enums
lib/NetHack/Variant.pm:    !$self->combo_defined()
lib/NetHack/Variant.pm:    || !( $self->rules() || $self->enum() );
lib/NetHack/Variant.pm:  #--- init the structure
lib/NetHack/Variant.pm:  #--- init the table
lib/NetHack/Variant.pm:  # value of -1 marks unavailable combo
lib/NetHack/Variant.pm:  foreach my $role (@{$self->roles()}) {
lib/NetHack/Variant.pm:    foreach my $race (@{$self->races()}) {
lib/NetHack/Variant.pm:      foreach my $align (@{$self->alignments()}) {
lib/NetHack/Variant.pm:        foreach my $gender (@{$self->genders()}) {
lib/NetHack/Variant.pm:          $val ||= $self->combo_valid($role, $race, $gender, $align);
lib/NetHack/Variant.pm:        $val = $val ? undef : -1;
lib/NetHack/Variant.pm:  my $ct = $self->combo_table();
lib/NetHack/Variant.pm:  if(!exists $ct->{'idx'}{$role}{$race}{$align}) {
lib/NetHack/Variant.pm:    die sprintf('Invalid character combination %s-%s-%s', $role, $race, $align);
lib/NetHack/Variant.pm:  ($i, $j, $k) = @{$ct->{'idx'}{$role}{$race}{$align}};
lib/NetHack/Variant.pm:    $ct->{'table'}[$i][$j][$k] = $val;
lib/NetHack/Variant.pm:  return $ct->{'table'}[$i][$j][$k];
lib/NetHack/Variant.pm:  foreach my $role (@{$self->roles()}) {
lib/NetHack/Variant.pm:    foreach my $race (@{$self->races()}) {
lib/NetHack/Variant.pm:      foreach my $align (@{$self->alignments()}) {
lib/NetHack/Variant.pm:        my $val = $self->combo_table_cell($role, $race, $align);
lib/NetHack/Variant.pm:# from Noble and there is no way to know which one it really is. The non-
lib/NHdb/Feeder/Cmdline.pm:# Processing of the command-line options for the feeder.
lib/NHdb/Feeder/Cmdline.pm:# --logfiles
lib/NHdb/Feeder/Cmdline.pm:# --variant=VARIANT
lib/NHdb/Feeder/Cmdline.pm:# --server=SERVER
lib/NHdb/Feeder/Cmdline.pm:# --logid=LOGID
lib/NHdb/Feeder/Cmdline.pm:# --purge
lib/NHdb/Feeder/Cmdline.pm:# remove all games matching criteria specified with --server, --variant
lib/NHdb/Feeder/Cmdline.pm:# and --logid
lib/NHdb/Feeder/Cmdline.pm:# --[no]oper
lib/NHdb/Feeder/Cmdline.pm:# --[no]static
lib/NHdb/Feeder/Cmdline.pm:# --pmap-add=SRCNAME/SRV=DSTNAME
lib/NHdb/Feeder/Cmdline.pm:# --pmap-remove=SRCNAME/SRV
lib/NHdb/Feeder/Cmdline.pm:# --pmap-list
lib/NHdb/Feeder/Cmdline.pm:# Initialize the object according to the command-line options given
lib/NHdb/Feeder/Cmdline.pm:    'logfiles'      => sub { $self->_set_show_logfiles(1);
lib/NHdb/Feeder/Cmdline.pm:                             $self->_set_no_lockfile(1); },
lib/NHdb/Feeder/Cmdline.pm:    'variant=s'     => sub { $self->_add_to('variants', $_[1]); },
lib/NHdb/Feeder/Cmdline.pm:    'server=s'      => sub { $self->_add_to('servers', $_[1]); },
lib/NHdb/Feeder/Cmdline.pm:    'logid=s'       => sub { $self->_set_logid($_[1]); },
lib/NHdb/Feeder/Cmdline.pm:    'purge'         => sub { $self->_set_purge(1); },
lib/NHdb/Feeder/Cmdline.pm:    'oper!'         => sub { $self->_set_operational($_[1]);
lib/NHdb/Feeder/Cmdline.pm:                             $self->_set_no_lockfile(1); },
lib/NHdb/Feeder/Cmdline.pm:    'static!'       => sub { $self->_set_static($_[1]);
lib/NHdb/Feeder/Cmdline.pm:                             $self->_set_no_lockfile(1); },
lib/NHdb/Feeder/Cmdline.pm:    'pmap-add=s'    => sub { $self->_add_to('pmap_add', $_[1]);
lib/NHdb/Feeder/Cmdline.pm:                             $self->_set_no_lockfile(1); },
lib/NHdb/Feeder/Cmdline.pm:    'pmap-remove=s' => sub { $self->_add_to('pmap_remove', $_[1]);
lib/NHdb/Feeder/Cmdline.pm:                             $self->_set_no_lockfile(1); },
lib/NHdb/Feeder/Cmdline.pm:    'pmap-list'     => sub { $self->_set_pmap_list(1);
lib/NHdb/Feeder/Cmdline.pm:                             $self->_set_no_lockfile(1); },
lib/NHdb/Feeder/Cmdline.pm:    print STDERR "Invalid command-line argument\n";
lib/NHdb/Feeder/Cmdline.pm:Usage: nhdb-feeder.pl [options]
lib/NHdb/Feeder/Cmdline.pm:  --help            get this information text
lib/NHdb/Feeder/Cmdline.pm:  --logfiles        display configured logfiles, then exit
lib/NHdb/Feeder/Cmdline.pm:  --variant=VAR     limit processing to specified variant(s)
lib/NHdb/Feeder/Cmdline.pm:  --server=SRV      limit processing to specified server(s)
lib/NHdb/Feeder/Cmdline.pm:  --logid=ID        limit processing to specified logid
lib/NHdb/Feeder/Cmdline.pm:  --purge           delete database content
lib/NHdb/Feeder/Cmdline.pm:  --oper            enable/disable source(s)
lib/NHdb/Feeder/Cmdline.pm:  --static          enable/disable static flag on source(s)
lib/NHdb/Feeder/Cmdline.pm:  --pmap-list       list existing player name mappings
lib/NHdb/Feeder/Cmdline.pm:  --pmap-add=MAP    add player name mapping(s)
lib/NHdb/Feeder/Cmdline.pm:  --pmap-remove=MAP remove player name mapping(s)
lib/NHdb/Utils.pm:# %u - username
lib/NHdb/Utils.pm:# %U - first letter of username
lib/NHdb/Utils.pm:# %s - start time (unix epoch)
lib/NHdb/Utils.pm:# %e - end time (unix epoch)
lib/NHdb/Utils.pm:# %E - end time (as YYYYMMDDHHMMSS)
lib/NHdb/Utils.pm:# %x - username before translation (as it appears in xlogfile)
lib/NHdb/Utils.pm:# %v - version number
lib/NHdb/Utils.pm:# %V - version number stripped of dots (ie 3.6.3 becomes 363)
lib/NHdb/Utils.pm:# %d - dumpfile (content of the 'dumpfile' xlogfile field)
lib/NHdb/Utils.pm:# %D - dumpfile processed for NH4 (_ replaced with :)
lib/NHdb/Utils.pm:# %S - contents of the src field (workaround for TNNT, FIXME: this needs
lib/NHdb/Utils.pm:  my $r_username = $data->{'name'};
lib/NHdb/Utils.pm:  my $r_uinitial = substr($data->{'name'}, 0, 1);
lib/NHdb/Utils.pm:  my $r_starttime = $data->{'starttime_raw'};
lib/NHdb/Utils.pm:  my $r_endtime = $data->{'endtime_raw'};
lib/NHdb/Utils.pm:  my $r_username_orig = $data->{'name_orig'};
lib/NHdb/Utils.pm:  my $r_version = $data->{'version'};
lib/NHdb/Utils.pm:  my $r_version_dotless = $data->{'version'} =~ s/\.//gr;
lib/NHdb/Utils.pm:  my $r_dumpfile = uri_escape($data->{'dumplog'});
lib/NHdb/Utils.pm:  my $r_src = $data->{'src'} // '';
lib/NHdb/Utils.pm:  my @et = gmtime($data->{'endtime_raw'});
lib/NHdb/Utils.pm:  my $r_dumpfile_nh4 = $data->{'dumplog'};
lib/NHdb/Utils.pm:    my $val = $vals->[$i];
lib/NHdb/Utils.pm:# arrayrefs to one-element arrays.
lib/NHdb/Utils.pm:# Version string mangling (cutting off the prefix, so "UNH-5.2" becomes "5.2"
lib/NHdb/Utils.pm:  $ver =~ s/^.*-//;
lib/NHdb/Db.pm:    if !is_blessed_hashref($_[0]) || !$_[0]->isa('NHdb::Config');
lib/NHdb/Db.pm:  my $c = $self->config()->config();
lib/NHdb/Db.pm:  my $id = $self->id();
lib/NHdb/Db.pm:  #--- reject unconfigured database connection id and connection specifics
lib/NHdb/Db.pm:    if !exists $c->{'db'}{$id};
lib/NHdb/Db.pm:  my $conn = $c->{'db'}{$id};
lib/NHdb/Db.pm:    if !$conn->{'dbname'};
lib/NHdb/Db.pm:    if !$conn->{'dbuser'};
lib/NHdb/Db.pm:  croak qq{Undefined password for database user "$conn->{'dbuser'}"}
lib/NHdb/Db.pm:    if !$c->{'auth'} || !$c->{'auth'}{$conn->{'dbuser'}};
lib/NHdb/Db.pm:  #--- create the source string
lib/NHdb/Db.pm:  my $src = 'dbi:Pg:dbname=' . $conn->{'dbname'};
lib/NHdb/Db.pm:  $src .= ';host=' . $conn->{'dbhost'} if $conn->{'dbhost'};
lib/NHdb/Db.pm:  #--- connect to the database
lib/NHdb/Db.pm:  my $dbh = DBI->connect(
lib/NHdb/Db.pm:    $conn->{'dbuser'},
lib/NHdb/Db.pm:    $c->{'auth'}{$conn->{'dbuser'}},
lib/NHdb/Config.pm:# Module for NHdb specific configuration and configuration-dependent stuff.
lib/NHdb/Config.pm:  my $js = JSON->new()->relaxed(1);
lib/NHdb/Config.pm:  #--- read the main config file
lib/NHdb/Config.pm:  my $def_json = path($Bin, 'cfg/nhdb_def.json')->slurp_raw();
lib/NHdb/Config.pm:  my $nhdb_def = $js->decode($def_json);
lib/NHdb/Config.pm:  #--- read the file with db passwords (if defined)
lib/NHdb/Config.pm:  if(exists $nhdb_def->{'auth'}) {
lib/NHdb/Config.pm:    $def_json = path($Bin, 'cfg', $nhdb_def->{'auth'})->slurp_raw();
lib/NHdb/Config.pm:    $nhdb_def->{'auth'} = $js->decode($def_json);
lib/NHdb/Config.pm:  my $c = $self->config();
lib/NHdb/Config.pm:    (grep { $name eq $_ } @{$c->{'feeder'}{'reject_name'}})
lib/NHdb/Config.pm:  my $c = $self->config();
lib/NHdb/Config.pm:    exists $c->{'feeder'}{'regular_fields'}
lib/NHdb/Config.pm:    && ref $c->{'feeder'}{'regular_fields'}
lib/NHdb/Config.pm:    return @{$c->{'feeder'}{'regular_fields'}}
lib/NHdb/Config.pm:  my $c = $self->config();
lib/NHdb/Config.pm:  foreach my $required_field (@{$c->{'feeder'}{'require_fields'}}) {
lib/NHdb/Config.pm:  my $c = $self->config();
lib/NHdb/Config.pm:      (grep { $variant eq $_ } @{$c->{'firsttoascend'}})
lib/NHdb/Config.pm:    return @{$c->{'firsttoascend'}};
lib/NHdb/Cmdline.pm:# Processing of the command-line options common to both feeder and stats.
lib/NHdb/Cmdline.pm:  my $attrval = $self->$where();
lib/NHdb/Cmdline.pm:    $self->$setter($attrval = []);
lib/NHdb/Cmdline.pm:  push(@$attrval, $self->_cmd_list_expand(@_));
lib/NHdb/Cmdline.pm:  my $value = $self->$option();
lib/NHdb/Cmdline.pm:# that some of the command-line options avoid this locking. Unsuccessful
lib/NHdb/Cmdline.pm:  my $lockfile = $self->lockfile;
lib/NHdb/Cmdline.pm:  #--- do nothing when we should not do locking
lib/NHdb/Cmdline.pm:  return if $self->no_lockfile();
lib/NHdb/Cmdline.pm:  #--- perform locking
lib/NHdb/Cmdline.pm:  die "Another instance running, exiting\n" if -f $lockfile;
lib/NHdb/Cmdline.pm:  unlink($self->lockfile);
lib/NHdb/Stats/Cmdline.pm:# Processing of the command-line options for the feeder.
lib/NHdb/Stats/Cmdline.pm:# the following attributes come from parsing the command-line options
lib/NHdb/Stats/Cmdline.pm:# Initialize the object according to the command-line options given
lib/NHdb/Stats/Cmdline.pm:    'variant=s' => sub { $self->_add_to('variants', $_[1]); },
lib/NHdb/Stats/Cmdline.pm:    'force'     => sub { $self->_set_force($_[1]); },
lib/NHdb/Stats/Cmdline.pm:    'player=s'  => sub { $self->_add_to('players', $_[1]); },
lib/NHdb/Stats/Cmdline.pm:    'players!'  => sub { $self->_set_process_players($_[1]); },
lib/NHdb/Stats/Cmdline.pm:    'aggr!'     => sub { $self->_set_process_aggregate($_[1]); },
lib/NHdb/Stats/Cmdline.pm:    'pages=s'   => sub { $self->_add_to('pages', $_[1]); },
lib/NHdb/Stats/Cmdline.pm:    'help'      => sub { $self->help(); exit(0); },
lib/NHdb/Stats/Cmdline.pm:    print STDERR "Invalid command-line argument\n";
lib/NHdb/Stats/Cmdline.pm:    $self->help();
lib/NHdb/Stats/Cmdline.pm:  if(ref($self->aggr_pages())) {
lib/NHdb/Stats/Cmdline.pm:    push(@pages, keys %{$self->aggr_pages()});
lib/NHdb/Stats/Cmdline.pm:  if(ref($self->summ_pages())) {
lib/NHdb/Stats/Cmdline.pm:    push(@pages, keys %{$self->summ_pages()});
lib/NHdb/Stats/Cmdline.pm:  print "Usage: nhdb-stats.pl [options]\n\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --help         get this information text\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --variant=VAR  limit processing to specified variant(s)\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --force        force processing of everything\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --player=NAME  update only given player\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --noplayers    disable generating player pages\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --noaggr       disable generating aggregate pages\n";
lib/NHdb/Stats/Cmdline.pm:  print "  --pages=PAGES  limit processing to specified pages (";
lib/NHdb/Stats/Cmdline.pm:# Helper methods to quickly determine whether --players, --variants and
lib/NHdb/Stats/Cmdline.pm:# --pages were specified
lib/NHdb/Stats/Cmdline.pm:  return scalar(@{$self->players()})
lib/NHdb/Stats/Cmdline.pm:  return scalar(@{$self->variants()})
lib/NHdb/Stats/Cmdline.pm:  return scalar(@{$self->pages()})
nhdb-stats.pl:# (c) 2013-2017 Borek Lupomesky
nhdb-stats.pl:#--- list of sources ('logfiles') loaded from database
nhdb-stats.pl:#--- Log4Perl instance
nhdb-stats.pl:#--- NetHack::Config instance
nhdb-stats.pl:#--- NHdb::Config instance
nhdb-stats.pl:my $nhdb = NHdb::Config->instance;
nhdb-stats.pl:#--- NHdb::Db instance (initalized later)
nhdb-stats.pl:#--- aggregate and summary pages generators
nhdb-stats.pl:my $lockfile = '/tmp/nhdb-stats.lock';
nhdb-stats.pl:my $http_root = $nhdb->config()->{'http_root'};
nhdb-stats.pl:my $tt = Template->new(
nhdb-stats.pl:  my $preproc   = shift;         # 4. subroutine to pre-process row
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  my $sth = $dbh->prepare($query);
nhdb-stats.pl:  my $r = $sth->execute(@args);
nhdb-stats.pl:  if(!$r) { return $sth->errstr(); }
nhdb-stats.pl:  while(my $row = $sth->fetchrow_hashref()) {
nhdb-stats.pl:      $row->{'n'} = $cnt_start;
nhdb-stats.pl:  $sth->finish();
nhdb-stats.pl:# Create list of player-variant pairs to be updated.
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:    $cmd_force,    # 1. --force specified
nhdb-stats.pl:    $cmd_variant,  # 2. list of variants from --variant
nhdb-stats.pl:    $cmd_player    # 3. list of players from --player
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  #--- get list of allowed variants
nhdb-stats.pl:  # of variants supplied through --variant cmdline option (cross-checked
nhdb-stats.pl:  my @variants_known = ('all', $nh->variants());
nhdb-stats.pl:  #--- display information
nhdb-stats.pl:  $logger->info('Getting list of player pages to update');
nhdb-stats.pl:  $logger->info('Forced processing enabled') if $cmd_force;
nhdb-stats.pl:  $logger->info('Restricted to variants: ', join(',', @variants_final))
nhdb-stats.pl:  $logger->info('Restricted to players: ', join(',', @$cmd_player))
nhdb-stats.pl:  #--- get list of all known player names
nhdb-stats.pl:  $logger->info('Loading list of all players');
nhdb-stats.pl:  $sth = $dbh->prepare(q{SELECT name FROM games GROUP BY name});
nhdb-stats.pl:  $r = $sth->execute();
nhdb-stats.pl:    my $errmsg = sprintf('Cannot get list of players (%s)', $sth->errstr());
nhdb-stats.pl:    $logger->error($errmsg);
nhdb-stats.pl:  while(my ($plr) = $sth->fetchrow_array()) {
nhdb-stats.pl:  $logger->info(sprintf('Loaded %d players', scalar(@player_list)));
nhdb-stats.pl:  #--- get list of existing (player, variant) combinations
nhdb-stats.pl:  #--- that have non-zero number of games in db
nhdb-stats.pl:  $logger->info('Loading list of (player,variant) combinations');
nhdb-stats.pl:  $sth = $dbh->prepare(
nhdb-stats.pl:  $r = $sth->execute();
nhdb-stats.pl:      'Cannot get list of player,variant combos (%s)', $sth->errstr()
nhdb-stats.pl:    $logger->error($errmsg);
nhdb-stats.pl:  while(my ($plr, $var) = $sth->fetchrow_array()) {
nhdb-stats.pl:  $logger->info(
nhdb-stats.pl:  #--- forced update enabled
nhdb-stats.pl:      #--- if list of players is specified on the cmdline, then
nhdb-stats.pl:      #--- use it as filter here
nhdb-stats.pl:      #--- create cartesian product, but restricted
nhdb-stats.pl:      #--- to existing player,variant combos
nhdb-stats.pl:    $logger->info(sprintf('Forcing update of %d pages', scalar(@pages_forced)));
nhdb-stats.pl:  #--- get list of updated players
nhdb-stats.pl:  $logger->info('Loading list of player updates');
nhdb-stats.pl:  $sth = $dbh->prepare(q{SELECT * FROM update WHERE name <> '' AND upflag IS TRUE});
nhdb-stats.pl:  $r = $sth->execute();
nhdb-stats.pl:      'Cannot get list of player updates (%s)', $sth->errstr()
nhdb-stats.pl:    $logger->error($errmsg);
nhdb-stats.pl:  while(my ($var, $plr) = $sth->fetchrow_array()) {
nhdb-stats.pl:    # NOTE: the matching is case-insensitive
nhdb-stats.pl:  $logger->info(
nhdb-stats.pl:      $cnt - scalar(@pages_updated)
nhdb-stats.pl:#  1) --force command-line option
nhdb-stats.pl:#  2) --variant command-line option
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  $logger->debug(
nhdb-stats.pl:  #--- list of allowed variants targets; anything not in this array
nhdb-stats.pl:  #--- is invalid
nhdb-stats.pl:  my @variants_known = ('all', $nh->variants());
nhdb-stats.pl:  $logger->debug('Known variants: (', join(',', @variants_known), ')');
nhdb-stats.pl:  #--- forced processing
nhdb-stats.pl:  #--- no forcing, using database
nhdb-stats.pl:    my $sth = $dbh->prepare(
nhdb-stats.pl:    my $re = $sth->execute();
nhdb-stats.pl:        "Failed to read from update table (%s)" . $sth->errstr()
nhdb-stats.pl:      $logger->error($errmsg);
nhdb-stats.pl:    while(my ($a) = $sth->fetchrow_array()) {
nhdb-stats.pl:  #--- validation
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  $logger->debug('update_schedule_variants() finished');
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  my $sth = $dbh->prepare('SELECT * FROM logfiles');
nhdb-stats.pl:  my $r = $sth->execute();
nhdb-stats.pl:    return sprintf('Failed to query database (%s)', $sth->errstr());
nhdb-stats.pl:  while(my $row = $sth->fetchrow_hashref()) {
nhdb-stats.pl:    my $logfiles_i  = $row->{'logfiles_i'};
nhdb-stats.pl:    $logfiles->{$logfiles_i} = $row;
nhdb-stats.pl:# --- this defines streak ordering and is just array of integers - row ids
nhdb-stats.pl:# --- into the 'streaks' table
nhdb-stats.pl:# --- this contains all the data needed; the %ROW is one row from join
nhdb-stats.pl:# --- query accross 'games', 'logfiles' and 'streaks' tables
nhdb-stats.pl:# 4. list streaks with at least this many games (no value or value of 0-1
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:    $num_games,       # 4. games-in-a-streak cutoff value
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  my %streaks;       # streaks_i-keyed hash with all info
nhdb-stats.pl:  #---------------------------------------------------------------------------
nhdb-stats.pl:  #--- get ordered list of streaks with turncounts ---------------------------
nhdb-stats.pl:  #---------------------------------------------------------------------------
nhdb-stats.pl:  #--- the query -> ( streaks_i, turns_sum, num_games, open )
nhdb-stats.pl:  #--- conditions
nhdb-stats.pl:  #--- assemble the query
nhdb-stats.pl:  #--- append query limit
nhdb-stats.pl:  #--- execute query
nhdb-stats.pl:  $sth = $dbh->prepare($query);
nhdb-stats.pl:  $r = $sth->execute(@args);
nhdb-stats.pl:  if(!$r) { return $sth->errstr(); }
nhdb-stats.pl:  while(my $row = $sth->fetchrow_hashref()) {
nhdb-stats.pl:    push(@streaks_ord, $row->{'streaks_i'});
nhdb-stats.pl:    $streaks{$row->{'streaks_i'}} = {
nhdb-stats.pl:      'turncount' => $row->{'turns_sum'},
nhdb-stats.pl:      'num_games' => $row->{'num_games'},
nhdb-stats.pl:      'open'      => $row->{'open'},
nhdb-stats.pl:  #-------------------------------------------------------------------------
nhdb-stats.pl:  #--- get list of streak games --------------------------------------------
nhdb-stats.pl:  #-------------------------------------------------------------------------
nhdb-stats.pl:  #--- prepare query
nhdb-stats.pl:  q{to_char(starttime,'YYYY-MM-DD HH24:MI') AS starttime_fmt, } .
nhdb-stats.pl:  q{to_char(endtime,'YYYY-MM-DD HH24:MI') AS endtime_fmt, } .
nhdb-stats.pl:  #--- conditions
nhdb-stats.pl:  #--- execute query
nhdb-stats.pl:  $sth = $dbh->prepare($query);
nhdb-stats.pl:  $r = $sth->execute(@args);
nhdb-stats.pl:  if(!$r) { return $sth->errstr(); }
nhdb-stats.pl:  while(my $row = $sth->fetchrow_hashref()) {
nhdb-stats.pl:    if(exists($streaks{$row->{'streaks_i'}})) {
nhdb-stats.pl:        @{$streaks{$row->{'streaks_i'}}{'games'}},
nhdb-stats.pl:      #--- save streak age (days from last game's endtime)
nhdb-stats.pl:      if(exists $streaks{$row->{'streaks_i'}}{'age'}) {
nhdb-stats.pl:        $streaks{$row->{'streaks_i'}}{'age'} = $row->{'age_day'}
nhdb-stats.pl:        if $streaks{$row->{'streaks_i'}}{'age'} > $row->{'age_day'};
nhdb-stats.pl:        $streaks{$row->{'streaks_i'}}{'age'} = $row->{'age_day'};
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  #--- processing
nhdb-stats.pl:    my $streak = $streaks->{$streaks_ord->[$i]};
nhdb-stats.pl:    my $games_num = $streak->{'num_games'};
nhdb-stats.pl:    my $game_first = $streak->{'games'}[0];
nhdb-stats.pl:    my $game_last = $streak->{'games'}[$games_num - 1];
nhdb-stats.pl:    $row->{'n'}          = $i + 1;
nhdb-stats.pl:    $row->{'wins'}       = $games_num;
nhdb-stats.pl:    $row->{'server'}     = $game_first->{'server'};
nhdb-stats.pl:    $row->{'open'}       = $streak->{'open'};
nhdb-stats.pl:    $row->{'variant'}    = $game_first->{'variant'};
nhdb-stats.pl:    $row->{'version'}    = nhdb_version($game_first->{'version'});
nhdb-stats.pl:    $row->{'start'}      = $game_first->{'endtime_fmt'};
nhdb-stats.pl:    $row->{'start_dump'} = $game_first->{'dump'};
nhdb-stats.pl:    $row->{'end'}        = $game_last->{'endtime_fmt'};
nhdb-stats.pl:    $row->{'end_dump'}   = $game_last->{'dump'};
nhdb-stats.pl:    $row->{'turns'}      = $streak->{'turncount'};
nhdb-stats.pl:    $row->{'name'}       = $game_first->{'name'};
nhdb-stats.pl:    $row->{'plrpage'}    = $game_first->{'plrpage'};
nhdb-stats.pl:    $row->{'name_orig'}  = $game_first->{'name_orig'};
nhdb-stats.pl:    $row->{'age'}        = $streak->{'age'};
nhdb-stats.pl:    $row->{'glist'}      = [];
nhdb-stats.pl:    for my $game (@{$streak->{'games'}}) {
nhdb-stats.pl:      $game->{'n'} = $games_cnt++;
nhdb-stats.pl:      push(@{$row->{'glist'}}, $game);
nhdb-stats.pl:    $row->{'version'}    = $game_first->{'version'};
nhdb-stats.pl:    if($game_first->{'version'} ne $game_last->{'version'}) {
nhdb-stats.pl:      $row->{'version'} = sprintf(
nhdb-stats.pl:        '%s-%s', $game_first->{'version'}, $game_last->{'version'}
nhdb-stats.pl:    #--- truncate time for games without endtime field
nhdb-stats.pl:    if($game_first->{'deathdate'}) {
nhdb-stats.pl:      $row->{'start'} =~ s/\s.*$//;
nhdb-stats.pl:    if($game_last->{'deathdate'}) {
nhdb-stats.pl:      $row->{'end'} =~ s/\s.*$//;
nhdb-stats.pl:  #--- return
nhdb-stats.pl:  my $logfiles_i = $row->{'logfiles_i'};
nhdb-stats.pl:  my $logfile = $logfiles->{$logfiles_i};
nhdb-stats.pl:  my $variant = $nh->variant($row->{'variant'});
nhdb-stats.pl:  #--- convert realtime to human-readable form
nhdb-stats.pl:  if($row->{'realtime'}) {
nhdb-stats.pl:    $row->{'realtime_raw'} = defined $row->{'realtime'} ? $row->{'realtime'} : 0;
nhdb-stats.pl:    $row->{'realtime'} = format_duration($row->{'realtime'});
nhdb-stats.pl:  #--- format version string
nhdb-stats.pl:  $row->{'version'} = nhdb_version($row->{'version'});
nhdb-stats.pl:  #--- include conducts in the ascended message
nhdb-stats.pl:  if($row->{'ascended'} && defined $row->{'conduct'}) {
nhdb-stats.pl:    my @c = $variant->conduct(@{$row}{'conduct', 'elbereths', 'achieve'});
nhdb-stats.pl:    $row->{'ncond'} = scalar(@c);
nhdb-stats.pl:    $row->{'tcond'} = join(' ', @c);
nhdb-stats.pl:      $row->{'death'} = 'ascended with all conducts broken';
nhdb-stats.pl:      $row->{'death'} = sprintf(
nhdb-stats.pl:        scalar(@c), (scalar(@c) == 1 ? '' : 's'), $row->{'tcond'}
nhdb-stats.pl:  #--- game dump URL
nhdb-stats.pl:  if($logfile->{'dumpurl'} && $row->{'endtime_raw'}) {
nhdb-stats.pl:    $row->{'dump'} = url_substitute(
nhdb-stats.pl:      $logfile->{'dumpurl'},
nhdb-stats.pl:  #--- realtime (aka duration)
nhdb-stats.pl:    $row->{'variant'} eq 'ace' ||
nhdb-stats.pl:    $row->{'variant'} eq 'nh4' ||
nhdb-stats.pl:    $row->{'variant'} eq 'nhf' ||
nhdb-stats.pl:    $row->{'variant'} eq 'dyn' ||
nhdb-stats.pl:    $row->{'variant'} eq 'fh'  ||
nhdb-stats.pl:    grep(/^bug360duration$/, @{$logfile->{'options'}})
nhdb-stats.pl:    $row->{'realtime'} = '';
nhdb-stats.pl:  #--- player page
nhdb-stats.pl:  $row->{'plrpage'} = url_substitute(
nhdb-stats.pl:    sprintf("players/%%U/%%u.%s.html", $row->{'variant'}),
nhdb-stats.pl:  #--- truncate time if needed
nhdb-stats.pl:  if($row->{'birthdate'}) {
nhdb-stats.pl:    $row->{'endtime_fmt'} =~ s/\s.*$//;
nhdb-stats.pl:  #--- assert data received
nhdb-stats.pl:  #--- create year/months counts in hash
nhdb-stats.pl:    $ascension->{'endtime'} =~ /^(\d{4})-(\d{2})-\d{2}\s/;
nhdb-stats.pl:  #--- now turn the data into an array
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  #--- return cached result
nhdb-stats.pl:  #--- calculation
nhdb-stats.pl:  #--- logging
nhdb-stats.pl:  $logger->debug('zscore() entry');
nhdb-stats.pl:  #--- zscore structure instantiation
nhdb-stats.pl:  #--- just return current state if already processed
nhdb-stats.pl:    $logger->debug('zscore() finish (cached)');
nhdb-stats.pl:  #--- zscore structure definition
nhdb-stats.pl:  # val ... z-score values (player->variant->role)
nhdb-stats.pl:  # max ... maximum values (variant->role)
nhdb-stats.pl:  #--- retrieve the data from database
nhdb-stats.pl:    $logger->error('zscore() failed, ', $ascs);
nhdb-stats.pl:  $logger->debug(sprintf('zscore() data loaded from db, %d rows', scalar(@$ascs)));
nhdb-stats.pl:  #--- get the counts
nhdb-stats.pl:    $counts{$row->{'name'}}{$row->{'variant'}}{lc($row->{'role'})}++;
nhdb-stats.pl:    $variants{$row->{'variant'}} = 0;
nhdb-stats.pl:  $logger->debug(
nhdb-stats.pl:  $logger->debug(
nhdb-stats.pl:  #--- get the z-numbers
nhdb-stats.pl:  # this calculates z-scores from the counts and stores them
nhdb-stats.pl:  # in hash of 'val'->PLAYER->VARIANT->ROLE; key 'all' contains
nhdb-stats.pl:  # sum of z-scores per-role and per-variant; therefore
nhdb-stats.pl:  # PLAYER->'all'->'all' is player's multi-variant z-score;
nhdb-stats.pl:  # PLAYER->VARIANT->'all' is player's z-score in given variant
nhdb-stats.pl:        $zval->{$plr}{'all'}{'all'} += $v;
nhdb-stats.pl:        $zval->{$plr}{$var}{$role}  += $v;
nhdb-stats.pl:        $zval->{$plr}{$var}{'all'}  += $v;
nhdb-stats.pl:        $zval->{$plr}{'all'}{$role} += $v;
nhdb-stats.pl:  #--- get the max z-values per (variant, role)
nhdb-stats.pl:    for my $var (keys %{$zval->{$plr}}) {
nhdb-stats.pl:      for my $role (keys %{$zval->{$plr}{$var}}) {
nhdb-stats.pl:        # per-variant per-role max values
nhdb-stats.pl:        $zmax->{$var}{$role} = $zval->{$plr}{$var}{$role}
nhdb-stats.pl:          if ($zmax->{$var}{$role} // 0) < $zval->{$plr}{$var}{$role};
nhdb-stats.pl:        # per-role all-variant max values
nhdb-stats.pl:        $zmax->{'all'}{$role} = $zval->{$plr}{$var}{$role}
nhdb-stats.pl:          if ($zmax->{'all'}{$role} // 0) < $zval->{$plr}{$var}{$role};
nhdb-stats.pl:      # per-variant max values
nhdb-stats.pl:      $zmax->{$var}{'all'} = $zval->{$plr}{$var}{'all'}
nhdb-stats.pl:        if ($zmax->{$var}{'all'} // 0) < $zval->{$plr}{$var}{'all'};
nhdb-stats.pl:    $zmax->{'all'}{'all'} = $zval->{$plr}{'all'}{'all'}
nhdb-stats.pl:      if ($zmax->{'all'}{'all'} // 0) < $zval->{$plr}{'all'}{'all'};
nhdb-stats.pl:  #--- sorting for use by player z-score ladders
nhdb-stats.pl:    #--- sort
nhdb-stats.pl:      ($zval->{$b}{$var}{'all'} // 0)
nhdb-stats.pl:      ($zval->{$a}{$var}{'all'} // 0)
nhdb-stats.pl:    #--- winnow empty entries
nhdb-stats.pl:      push(@{$zord->{$var}}, $plr) if exists $zval->{$plr}{$var}{'all'};
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  $logger->debug('zscore() finish (uncached)');
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  #--- init
nhdb-stats.pl:  $logger->info(
nhdb-stats.pl:  push(@variants, $nh->variants());
nhdb-stats.pl:  #--- select source view
nhdb-stats.pl:    $logger->error("Undefined page '$page' in gen_page_recent()");
nhdb-stats.pl:  #--- prepare query;
nhdb-stats.pl:  #--- pull data from database
nhdb-stats.pl:  $logger->debug($query_lst);
nhdb-stats.pl:  #--- supply additional data
nhdb-stats.pl:  $data{'variants'} = [ 'all', $nh->variants() ];
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  #--- process template
nhdb-stats.pl:  $tt->process(
nhdb-stats.pl:  ) or die $tt->error();
nhdb-stats.pl:# Generate individual player page for a single variant (including pseudo-
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  #--- info
nhdb-stats.pl:  $logger->info(sprintf('Creating page: @%s/%s', $name, $variant));
nhdb-stats.pl:  #=== z-score ==============================================================
nhdb-stats.pl:  $data{'games_count_all'} = int($result->[0]{'count'});
nhdb-stats.pl:  $data{'games_count_scum'} = $result->[0]{'count'};
nhdb-stats.pl:  $data{'games_first'} = $result->[0];
nhdb-stats.pl:    $query, $data{'games_count_all'}, -1,
nhdb-stats.pl:  $data{'games_last'} = $result->[0];
nhdb-stats.pl:  #=== total play-time =====================================================
nhdb-stats.pl:    $data{'total_duration'} = format_duration_plr($result->[0]{'sum'});
nhdb-stats.pl:  if($variant eq 'all' || $nh->variant($variant)->combo_defined()) {
nhdb-stats.pl:      $roles_all{$r->{'role'}} = $r->{'count'};
nhdb-stats.pl:      $roles_asc{$r->{'role'}} = $r->{'count'};
nhdb-stats.pl:      $races_all{$r->{'race'}} = $r->{'count'};
nhdb-stats.pl:      $races_asc{$r->{'race'}} = $r->{'count'};
nhdb-stats.pl:      $align_all{$r->{'align'}} = $r->{'count'};
nhdb-stats.pl:      $align_asc{$r->{'align'}} = $r->{'count'};
nhdb-stats.pl:  #--- some auxiliary metadata
nhdb-stats.pl:    $data{'streaks_count'}{'all'}++ if $row->{'wins'} > 1;
nhdb-stats.pl:    $data{'streaks_count'}{'open'}++ if $row->{'open'};
nhdb-stats.pl:  # nh_roles  -- all known roles for given variant
nhdb-stats.pl:  # nh_races  -- all known races for given variant
nhdb-stats.pl:  # nh_aligns -- all known aligments
nhdb-stats.pl:  # cur_time  -- current time (formatted)
nhdb-stats.pl:  # name      -- player name
nhdb-stats.pl:  # variant   -- variant (including 'all')
nhdb-stats.pl:  # variants  -- all supported variants
nhdb-stats.pl:  # vardef    -- contains variant full-names
nhdb-stats.pl:  # result_*  -- various result tables/datasets
nhdb-stats.pl:  #--- if variant is 'all', list only the canonical roles/races/alignments
nhdb-stats.pl:  my $nv = $nh->variant($variant eq 'all' ? 'nh' : $variant);
nhdb-stats.pl:  #--- z-roles -- roles shown in z-score table
nhdb-stats.pl:  # normally all roles in a variant are shown in the z-score breakdown table,
nhdb-stats.pl:  if($nv->roles()) {
nhdb-stats.pl:    $data{'z_roles'} = [ @{$nv->roles()} ];
nhdb-stats.pl:  #--- the rest
nhdb-stats.pl:  $data{'nh_roles'} = $nv->roles();
nhdb-stats.pl:  $data{'nh_races'} = $nv->races();
nhdb-stats.pl:  $data{'nh_aligns'} = $nv->alignments();
nhdb-stats.pl:    [ 'all', $nh->variants() ],
nhdb-stats.pl:    [ keys %{$player_combos->{$name}} ]
nhdb-stats.pl:  $data{'vardef'} = $nh->variant_names();
nhdb-stats.pl:  #--- determine filename
nhdb-stats.pl:  #--- process template
nhdb-stats.pl:  if(!$tt->process('player.tt', \%data, $file)) {
nhdb-stats.pl:    $logger->error(sprintf(q{Creating page '@%s/%s' failed, }, $name, $variant));
nhdb-stats.pl:    die $tt->error();
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:# --- this defines streak ordering and is just array of integeres - row ids
nhdb-stats.pl:# --- into the 'streaks' table
nhdb-stats.pl:# --- this contains all the data needed; the %ROW is one row from join
nhdb-stats.pl:# --- query accross 'games', 'logfiles' and 'streaks' tables
nhdb-stats.pl:  #--- init
nhdb-stats.pl:  $logger->info('Creating page: Streaks/', $variant);
nhdb-stats.pl:  push(@variants, $nh->variants());
nhdb-stats.pl:  #--- load streak list
nhdb-stats.pl:  #--- reprocessing for TT2
nhdb-stats.pl:  #--- supply additional data
nhdb-stats.pl:  $data{'variants'} = [ 'all', $nh->variants() ];
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  #--- process template
nhdb-stats.pl:  if(!$tt->process(
nhdb-stats.pl:    $logger->error("Failed to create page 'Streaks/$variant'");
nhdb-stats.pl:    die $tt->error();
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  #--- info
nhdb-stats.pl:  $logger->info('Creating page: About');
nhdb-stats.pl:  #--- run a query
nhdb-stats.pl:    $logger->error($result);
nhdb-stats.pl:  #--- URL to local logfiles
nhdb-stats.pl:  $data{'urlpath'} = $nhdb->config()->{'logs'}{'urlpath'};
nhdb-stats.pl:  #--- generate page
nhdb-stats.pl:  if(!$tt->process('about.tt', \%data, 'about.html')) {
nhdb-stats.pl:    $logger->error(q{Failed to create page 'About', }, $tt->error());
nhdb-stats.pl:    die $tt->error();
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  my @variants = $nh->variants();
nhdb-stats.pl:  my $dbh = $db->handle();
nhdb-stats.pl:  #--- info
nhdb-stats.pl:  $logger->info('Creating page: Front');
nhdb-stats.pl:  #--- perform database pull
nhdb-stats.pl:    #--- check if any games exist for given variant
nhdb-stats.pl:    my $sth = $dbh->prepare($query);
nhdb-stats.pl:    my $r = $sth->execute($variant);
nhdb-stats.pl:      $logger->error(q{Failed to create page 'Front' (1), }, $sth->errstr());
nhdb-stats.pl:      die $sth->errstr();
nhdb-stats.pl:    $sth->finish();
nhdb-stats.pl:    #--- retrieve the last won game
nhdb-stats.pl:    $sth = $dbh->prepare($query);
nhdb-stats.pl:    $r = $sth->execute($variant);
nhdb-stats.pl:      $logger->error(q{Failed to create page 'Front' (2), }, $sth->errstr());
nhdb-stats.pl:      die $sth->errstr();
nhdb-stats.pl:      my $row = $sth->fetchrow_hashref();
nhdb-stats.pl:      $row->{'age'} = fmt_age(
nhdb-stats.pl:        $row->{'age_years'},
nhdb-stats.pl:        $row->{'age_months'},
nhdb-stats.pl:        $row->{'age_days'},
nhdb-stats.pl:        $row->{'age_hours'}
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #--- retrieve currently open streaks ----------------------------------------
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:    $logger->error(q{Could not load streaks: }, $streaks_ord);
nhdb-stats.pl:  $logger->debug(
nhdb-stats.pl:  #--- streak reprocessing
nhdb-stats.pl:    if($entry->{'open'} && $entry->{'age'} < 90) {
nhdb-stats.pl:      $entry->{'n'} = $i++;
nhdb-stats.pl:      $entry->{'start'} =~ s/\s\d{2}:\d{2}$//;
nhdb-stats.pl:      $entry->{'end'} =~ s/\s\d{2}:\d{2}$//;
nhdb-stats.pl:  #--- save the result
nhdb-stats.pl:  $logger->debug(
nhdb-stats.pl:      scalar(@$streaks_proc_1) - scalar(@$streaks_proc_2)
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #--- retrieve recent ascensions ---------------------------------------------
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #--- sort the results
nhdb-stats.pl:  #--- generate page
nhdb-stats.pl:  $data{'vardef'} = $nh->variant_names();
nhdb-stats.pl:  if(!$tt->process('front.tt', \%data, 'index.html')) {
nhdb-stats.pl:    $logger->error(q{Failed to create page 'Front' (3), }, $tt->error());
nhdb-stats.pl:    die $tt->error();
nhdb-stats.pl:  #--- finish
nhdb-stats.pl:  my $nv = $nh->variant($variant eq 'all' ? 'nh' : $variant);
nhdb-stats.pl:  #--- info
nhdb-stats.pl:  $logger->info('Creating page: Z-scores/', $variant);
nhdb-stats.pl:  #--- calc and sort z-scores
nhdb-stats.pl:  #--- supply additional data
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  $data{'variants'} = [ 'all', $nh->variants() ];
nhdb-stats.pl:  #--- following key holds roles that are included in the z-score table
nhdb-stats.pl:  #--- for variants that have enumerated their roles in the configuration,
nhdb-stats.pl:  #--- this simply lists all of them plus 'all'; for variants that do not
nhdb-stats.pl:  #--- have their roles listed (such as SLASH'EM Extended), this works
nhdb-stats.pl:  #--- differently: we only list roles that have ascending games.
nhdb-stats.pl:  if(!$nv->roles()) {
nhdb-stats.pl:    $data{'z_roles'} = [ 'all', @{$nv->roles()} ];
nhdb-stats.pl:  #--- process template
nhdb-stats.pl:  $tt->process(
nhdb-stats.pl:  ) or die $tt->error();
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  #--- init
nhdb-stats.pl:  $logger->info('Creating page: Conducts/', $variant);
nhdb-stats.pl:  #--- query database
nhdb-stats.pl:    $logger->error(
nhdb-stats.pl:  #--- supply additional data
nhdb-stats.pl:  $data{'variants'} = [ 'all', $nh->variants() ];
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  #--- process template
nhdb-stats.pl:  $tt->process(
nhdb-stats.pl:  ) or die $tt->error();
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  #--- init
nhdb-stats.pl:  $logger->info('Creating page: Lowscore/', $variant);
nhdb-stats.pl:  #--- prepare query
nhdb-stats.pl:  #--- perform query
nhdb-stats.pl:    $logger->error(
nhdb-stats.pl:  #--- supply additional data
nhdb-stats.pl:  $data{'variants'} = [ 'all', $nh->variants() ];
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  #--- process template
nhdb-stats.pl:  $tt->process(
nhdb-stats.pl:  ) or die $tt->error();
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- don't generate if not enable in the config (we do not do
nhdb-stats.pl:  #--- 'first to ascend' for all variants)
nhdb-stats.pl:  return if !$nhdb->first_to_ascend($variant);
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  my $nv = $nh->variant($variant);
nhdb-stats.pl:  #--- processing of the database rows
nhdb-stats.pl:        $row->{$1} = $row->{$k};
nhdb-stats.pl:        delete $row->{$k};
nhdb-stats.pl:  #--- init
nhdb-stats.pl:  $logger->info('Creating page: First-to-ascend/', $variant);
nhdb-stats.pl:  #--- initialize combo table
nhdb-stats.pl:  $data{'table'} = $nv->combo_table()->{'table'};
nhdb-stats.pl:  $data{'roles'} = $nv->roles();
nhdb-stats.pl:  $data{'races'} = $nv->races();
nhdb-stats.pl:  $data{'genders'} = $nv->genders();
nhdb-stats.pl:  $data{'aligns'} = $nv->alignments();
nhdb-stats.pl:  $data{'roles_def'} = $nh->config()->{'nh_roles_def'};
nhdb-stats.pl:  $data{'races_def'} = $nh->config()->{'nh_races_def'};
nhdb-stats.pl:  #--- query database
nhdb-stats.pl:  #--- process the data
nhdb-stats.pl:    my $row = $re->[$i];
nhdb-stats.pl:    #--- add the entries to combo table
nhdb-stats.pl:    $nv->combo_table_cell(
nhdb-stats.pl:      $row->{'role'}, $row->{'race'}, $row->{'align'}, $row->{'name'}
nhdb-stats.pl:  #--- unascended combos, combos by player
nhdb-stats.pl:  $nv->combo_table_iterate(sub {
nhdb-stats.pl:        sprintf('%s-%s-%s', ucfirst($role), ucfirst($race), ucfirst($align))
nhdb-stats.pl:    if($val && $val ne '-1') {
nhdb-stats.pl:        sprintf('%s-%s-%s', ucfirst($role), ucfirst($race), ucfirst($align))
nhdb-stats.pl:  #--- create sorted index for 'byplayer'
nhdb-stats.pl:      my ($plr_a) = grep { $_->{'name'} eq $a } @$re;
nhdb-stats.pl:      my ($plr_b) = grep { $_->{'name'} eq $b } @$re;
nhdb-stats.pl:      $plr_a->{'n'} <=> $plr_b->{'n'};
nhdb-stats.pl:  #--- auxiliary data
nhdb-stats.pl:  $data{'variants'} = [ $nhdb->first_to_ascend() ];
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  #--- render template
nhdb-stats.pl:  if(!$tt->process('firstasc.tt', \%data, "firstasc.$variant.html")) {
nhdb-stats.pl:    $logger->error(q{Failed to render page firstasc.tt'}, $tt->error());
nhdb-stats.pl:    die $tt->error();
nhdb-stats.pl:# Generate Fastest Game-time page.
nhdb-stats.pl:  #--- arguments
nhdb-stats.pl:  #--- other variables
nhdb-stats.pl:  #--- init
nhdb-stats.pl:  $logger->info('Creating page: Game-time/', $variant);
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #--- top 100 lowest turncount games -----------------------------------------
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #--- per-player counts for sub-N turns games --------------------------------
nhdb-stats.pl:  #----------------------------------------------------------------------------
nhdb-stats.pl:  #--- auxiliary data
nhdb-stats.pl:  $data{'variants'} = [ 'all', $nh->variants() ];
nhdb-stats.pl:  $data{'vardef'}   = $nh->variant_names();
nhdb-stats.pl:  #--- render template
nhdb-stats.pl:  if(!$tt->process('gametime.tt', \%data, "gametime.$variant.html")) {
nhdb-stats.pl:    $logger->error(q{Failed to render page gametime.tt'}, $tt->error());
nhdb-stats.pl:    die $tt->error();
nhdb-stats.pl:#--- initialize logging
nhdb-stats.pl:Log::Log4perl->init('cfg/logging.conf');
nhdb-stats.pl:#--- title
nhdb-stats.pl:$logger->info('NetHack Scoreboard / Stats');
nhdb-stats.pl:$logger->info('(c) 2013-17 Borek Lupomesky');
nhdb-stats.pl:$logger->info('---');
nhdb-stats.pl:#--- process command-line
nhdb-stats.pl:my $cmd = NHdb::Stats::Cmdline->instance(
nhdb-stats.pl:# debugging log of command-lines options as we parsed them
nhdb-stats.pl:$logger_cmd->debug('cmd_variant = (', join(',', @{$cmd->variants()}), ')');
nhdb-stats.pl:$logger_cmd->debug('cmd_force = ', $cmd->option_state('force'));
nhdb-stats.pl:$logger_cmd->debug('cmd_players = ', $cmd->option_state('process_players'));
nhdb-stats.pl:$logger_cmd->debug('cmd_player = (', join(',', @{$cmd->players()}), ')');
nhdb-stats.pl:$logger_cmd->debug('cmd_aggr = ', $cmd->process_aggregate() ? 'on' : 'off');
nhdb-stats.pl:$logger_cmd->debug('cmd_pages = (', join(',', @{$cmd->pages()}), ')');
nhdb-stats.pl:$logger_cmd->debug('---');
nhdb-stats.pl:#--- lock file check/open
nhdb-stats.pl:  $cmd->lock;
nhdb-stats.pl:  $logger->warn($_);
nhdb-stats.pl:#--- connect to database
nhdb-stats.pl:$db = NHdb::Db->new(id => 'nhdbstats', config => $nhdb);
nhdb-stats.pl:my $dbh = $db->handle();
nhdb-stats.pl:$logger->info('Connected to database');
nhdb-stats.pl:#--- load list of logfiles
nhdb-stats.pl:$logger->info('Loaded list of logfiles');
nhdb-stats.pl:#--- read what is to be updated
nhdb-stats.pl:if($cmd->process_aggregate()) {
nhdb-stats.pl:    $cmd->force(),
nhdb-stats.pl:    $cmd->variants(),
nhdb-stats.pl:    $logger->info(
nhdb-stats.pl:    $logger->info('No new data received');
nhdb-stats.pl:#--- generate aggregate pages
nhdb-stats.pl:    #--- regular stats
nhdb-stats.pl:      next if $cmd->has_pages() && !grep { $page eq $_ } @{$cmd->pages()};
nhdb-stats.pl:      $aggr_pages{$page}->($var);
nhdb-stats.pl:    #--- clear update flag
nhdb-stats.pl:    $dbh->do(
nhdb-stats.pl:#--- generate per-player pages
nhdb-stats.pl:if($cmd->process_players()) {
nhdb-stats.pl:    $cmd->force(), $cmd->variants(), $cmd->players()
nhdb-stats.pl:    $dbh->do(
nhdb-stats.pl:      undef, $pg->[1], $pg->[0]
nhdb-stats.pl:#--- front and about page
nhdb-stats.pl:# still be disabled by --noaggr). Both these pages contain age information that
nhdb-stats.pl:if($cmd->process_aggregate()) {
nhdb-stats.pl:    next if $cmd->has_pages && !grep { $page eq $_ } @{$cmd->pages()};
nhdb-stats.pl:    $summ_pages{$page}->();
nhdb-stats.pl:#--- release lock file
nhdb-stats.pl:$cmd->unlock;
css/default.css:/*--- generic ---*/
css/default.css:  text-align: right;
css/default.css:/*--- ---*/
css/default.css:  font-family: "Trebuchet MS", "Tahoma", "Verdana", "Sans-Serif";
css/default.css:  font-size: 12px;
css/default.css:  font-family: "Lucida Grande", "Trebuchet MS", "Sans-Serif";
css/default.css:  margin-bottom: 3px;
css/default.css:  border-bottom: 2px solid #eee;
css/default.css:  margin-bottom: 7px;
css/default.css:  margin-top: 10px;
css/default.css:  margin-bottom: 3px;
css/default.css:  margin-bottom: 2px;
css/default.css:  border-collapse: collapse;
css/default.css:  font-size: 11px;
css/default.css:  text-align: left;
css/default.css:  border-top: 2px solid #ddd;
css/default.css:  border-bottom: 2px solid #ddd;
css/default.css:tr:nth-child(even) {
css/default.css:  font-weight: bold;
css/default.css:    margin-top: 0px;
css/default.css:    text-align: right;
css/default.css:    padding-top: 3px;
css/default.css:    padding-bottom: 3px;
css/default.css:    padding-right: 15px;
css/default.css:    text-decoration: none;
css/default.css:    background-color: #ff0;
css/default.css:    border-collapse: collapse;
css/default.css:  vertical-align: top;
css/default.css:  vertical-align: top;
css/default.css:    font-weight: bold;
css/default.css:    padding-left: 3px;
css/default.css:    padding-right: 3px;
css/default.css:    font-family: Monospace;
css/default.css:    font-family: Monospace;
css/default.css:    text-align: right;
css/default.css:    text-align: center;
css/default.css:    font-size: xx-small;
css/default.css:  display: table-cell;
css/default.css:/*--- Mandevil custom stuff here */
css/default.css:  font-weight : bold;
css/default.css:  padding-left : 0.2em;
css/default.css:  padding-right : 0.2em;
css/default.css:  white-space : nowrap;
css/default.css:  font-weight : bold;
css/default.css:  padding-left : 0.1em;
css/default.css:  padding-right : 0.1em;
css/default.css:  font-weight : bold;
css/default.css:  text-align : center;
css/default.css:  text-align : center;
css/default.css:  font-weight : normal;
css/default.css:  text-align : center;
css/default.css:  font-weight : normal;
css/default.css:  text-align : right;
css/default.css:  background-color : rgb(240,240,240) !important;
css/default.css:  text-decoration : none;
css/default.css:  text-decoration : underline;
css/default.css:  font-weight : bold;
css/default.css:  font-weight : bold;
css/default.css:  font-size : medium;
css/default.css:/*--- tablesorter styles ---*/
css/default.css:  padding-right : 1.4em;
css/default.css:  background-repeat: no-repeat; 
css/default.css:  background-position: center right; 
css/default.css:  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMSA5IiBoZWlnaHQ9IjkiIHdpZHRoPSIyMSI+PHBhdGggZD0iTTExLjczMyA5TDggNWg4bC00LjI2NyA0bTAtOUw4IDRoOGwtNC4yNjctNCIgZmlsbC1ydWxlPSJldmVub2RkIi8+PC9zdmc+");
css/default.css:  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMSA5IiBoZWlnaHQ9IjkiIHdpZHRoPSIyMSI+PHBhdGggZD0iTTggNWwzLjczMiA0TDE2IDVoLTEuMDY2bC0zLjIwMiAzLTIuNzk4LTNIOHpNMTEuNzMzIDBMOCA0aDhsLTQuMjY3LTQiIGZpbGwtcnVsZT0iZXZlbm9kZCIvPjwvc3ZnPg==");
css/default.css:  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyMSIgaGVpZ2h0PSI5IiB2aWV3Qm94PSIwIDAgMjEgOSI+PHBhdGggZD0iTTggNGwzLjczMi00TDE2IDRoLTEuMDY2bC0zLjIwMi0zLTIuNzk4IDNIOHpNMTEuNzMzIDlMOCA1aDhsLTQuMjY3IDQiIGZpbGwtcnVsZT0iZXZlbm9kZCIvPjwvc3ZnPg==");
css/default.css:  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMSA5IiBoZWlnaHQ9IjkiIHdpZHRoPSIyMSI+PHBhdGggZD0iTTExLjczMyAwTDggNGg4bC00LjI2Ny00IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4=");
css/default.css:  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMSA5IiBoZWlnaHQ9IjkiIHdpZHRoPSIyMSI+PHBhdGggZD0iTTExLjczMyA5TDggNWg4bC00LjI2NyA0IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4=");
css/default.css:/*--- streaks ---*/
css/default.css:SPAN.streak-open {
css/default.css:  font-weight : bold;
css/default.css:/*--- front ---*/
css/default.css:  font-size : smaller;
css/default.css:/*--- z-scores ---*/
css/default.css:  background-color : green;
css/default.css:  padding-left : 2px;
css/default.css:  padding-right : 2px;
css/default.css:/*--- special for recent games/ascensions ---*/
css/default.css:  background-color : white;
css/default.css:  font-weight      : normal;
css/default.css:  font-size        : smaller;
css/default.css:  background-color : white;
css/default.css:  border-top       : 1px dotted #ddd;
css/main.css:  font-family: 'Open Sans', sans-serif;
css/main.css:  font-size: 80%;
css/main.css:  border-collapse: collapse;
css/main.css:  vertical-align: top;
css/main.css:  text-align: left;
css/main.css:tr:nth-child(even) {
Binary file img/favicon.psd matches
Binary file img/favicon.png matches
Binary file .nhdb-feeder.pl.swp matches
README.md:This is the code used to run [NetHack Scoreboard](https://scoreboard.xd.cm/) web site. The code consists of two main components: *feeder* and *stats generator*. The feeder retrieves [xlogfiles](http://nethackwiki.com/wiki/Xlogfile) from public NetHack servers, parses them and stores the parsed log entries in a back-end database. The stats generator then uses this data to generate static HTML pages with various statistics, including personal pages.
README.md:-----
README.md:JSON (perl-JSON on fedora/dnf)
README.md:Path::Tiny (perl-Path-Tiny dnf)
README.md:-----
README.md:-----
README.md:* **Add Average Realtime And Average Gametime To Per-Variant Stats** // Can't be done for aggregates since realtime is measured differently or completely unavailable in some variants and gametime depends on variant (some variants have too different gameplay to be comparable)
README.md:* **Pseudovariant 'var'** // This would be pseudo-variant that would aggregate all variants but vanilla NetHack.
README.md:* **Per-Player Conduct Achievements** //
README.md:for per-player combo page, maybe some more later (but the code should be 
README.md:-----
README.md:## Command-line parameters
README.md:All the options that suply variants, servers or player names can be either used multiple times on the command-line, or they can have aggregate multiple strings by joining them with commas. Example:
README.md:     nhdb-feeder --variant=all --variant=nh --variant=nh4
README.md:     nhdb-feeder --variant=all,nh,nh4
README.md:### nhdb-feeder.pl
README.md:**--logfiles**  
README.md:**--server**=*server*  
README.md:with it), use `--variant` to further limit processing to single source.
README.md:**--variant**=*variant*  
README.md:Limit processing only to variant specified by its short-code (such as "nh", "unh" etc.)
README.md:**--logid**=*id*  
README.md:Limit processing only to logfiles specified by their log ids. Log id is NHS's internal identification of a configured logfile. The `--logfiles` option will display these id's.
README.md:**--purge**  
README.md:Erase all database entries that match `--logid`, `--server` and `--variant` options. If used alone without any specification, all the entries are deleted.
README.md:**--oper**, **--nooper**  
README.md:**--static**, **--nostatic**  
README.md:Make selected sources static (or non-static), ie. never try to download the source's configured xlogfile, but still
README.md:**--pmap-list**  
README.md:**--pmap-add**=*SRCNAME*/*SERVER*=*DSTNAME*  
README.md:*dstname*. Multiple translations can be added at the same time and this can be combined with `--pmap-remove`.
README.md:**--pmap-remove**=*SRCNAME*/*SERVER*  
README.md:Remove existing translation. Multiple translations can be removed at the same time and this can be combined with `--pmap-add`.
README.md:### nhdb-stats.pl
README.md:**--noaggr**  
README.md:**--force**  
README.md:Force processing of all variants and players, even if they do not need updating. Note, that regenerating all players' pages takes very long time. If you just want force regenerating aggregate pages only, use the `--noplayers` option along with `--force`.
README.md:**--variant**=*variant*  
README.md:**--noplayers**  
README.md:**--player**=*player*  
templates/topmenu.tt:  mnu     - name of the current menu
templates/topmenu.tt:  lvl     - nesting depth (0 or 2 currently)
templates/topmenu.tt:  var     - variant
templates/topmenu.tt:  devlink - add link to devnull pages
templates/topmenu.tt:[%- IF lvl == 2; SET path = "../../"; END -%]
templates/topmenu.tt:[%- IF devlink -%]
templates/topmenu.tt:[%- END -%]
templates/topmenu.tt:[%- IF mnu != "front" -%]
templates/topmenu.tt:  [%- IF lvl == 2 -%]
templates/topmenu.tt:  [%- ELSE -%]
templates/topmenu.tt:  [%- END -%]
templates/topmenu.tt:[%- END -%]
templates/topmenu.tt:[%- IF mnu != "recent" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "ascended" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "streaks" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "zscore" -%]
templates/topmenu.tt:  <a href="[% path %]zscore.[% var %].html">Z-scores</a> |
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "conduct" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "lowscore" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "gametime" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "firstasc" -%]
templates/topmenu.tt:[%- END %]
templates/topmenu.tt:[%- IF mnu != "about" -%]
templates/topmenu.tt:[%- END -%]
templates/ascended.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/ascended.tt:  <meta charset="utf-8" />
templates/lowscore.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/lowscore.tt:  <meta charset="utf-8">
templates/recent.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/recent.tt:  <meta charset="utf-8" />
templates/recent.tt:[% IF result_ascended.size -%]
templates/recent.tt:[% END -%]
templates/tab_ascended.tt:  <th data-sorter="true">&nbsp;</th>
templates/tab_ascended.tt:[%- IF NOT devnull -%]
templates/tab_ascended.tt:[%- END -%]
templates/tab_ascended.tt:[%- IF not name -%]
templates/tab_ascended.tt:[%- END -%]
templates/tab_ascended.tt:  <th data-sorter="true">character</th>
templates/tab_ascended.tt:  <th data-sorter="custkey">points</th>
templates/tab_ascended.tt:  <th data-sorter="true">turns&nbsp;&nbsp;</th>
templates/tab_ascended.tt:  <th data-sorter="custkey">duration</th>
templates/tab_ascended.tt:  <th data-sorter="custkey">dlvl&nbsp;</th>
templates/tab_ascended.tt:  <th data-sorter="custkey">HP</th>
templates/tab_ascended.tt:  <th data-sorter="custkey">time</th>
templates/tab_ascended.tt:  <th colspan="2" data-sorter="true">conducts</th>
templates/tab_ascended.tt:[%- IF NOT devnull -%]
templates/tab_ascended.tt:[%- END -%]
templates/tab_ascended.tt:[%- IF not name -%]
templates/tab_ascended.tt:  [%- IF devnull; THEN; row.name = row.name_orig; END -%]
templates/tab_ascended.tt:[%- END %]
templates/tab_ascended.tt:  [%- IF devnull; THEN; row.gender = row.gender0; row.align = row.align0; END -%]
templates/tab_ascended.tt:  <td>[% row.role %]-[% row.race %]-[% row.gender %]-[% row.align %]</td>
templates/tab_ascended.tt:[% IF row.dump -%]
templates/tab_ascended.tt:  <td class="numeric" data-sortkey="[% row.points %]"><a href="[% row.dump %]">[% number(row.points) %]</a></td>
templates/tab_ascended.tt:[%- ELSE -%]
templates/tab_ascended.tt:  <td class="numeric" data-sortkey="[% row.points %]">[% number(row.points) %]</td>
templates/tab_ascended.tt:[%- END %]
templates/tab_ascended.tt:  <td class="numeric" data-sortkey="[% row.realtime_raw %]">[% row.realtime %]</td>
templates/tab_ascended.tt:  <td class="numeric" data-sortkey="[%row.maxlvl %]">[% row.deathlev %]/[% row.maxlvl %]</td>
templates/tab_ascended.tt:  <td class="numeric" data-sortkey="[% row.maxhp %]">[% row.hp %]/[% row.maxhp %]</td>
templates/tab_ascended.tt:[%- END %]
templates/front.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/front.tt:  <meta charset="utf-8" />
templates/front.tt:<td>[% row.role %]-[% row.race %]-[% row.gender %]-[% row.align %]</td>
templates/front.tt:[% IF row.dump -%]
templates/front.tt:<td class="numeric" data-sortkey="[% row.points %]"><a href="[% row.dump %]">[% number(row.points) %]</a></td>
templates/front.tt:[%- ELSE -%]
templates/front.tt:<td class="numeric" data-sortkey="[% row.points %]">[% number(row.points) %]</td>
templates/front.tt:[%- END %]
templates/front.tt:<td class="numeric" data-sortkey="[% row.realtime_raw %]">[% row.realtime %]</td>
templates/front.tt:<td class="numeric" data-sortkey="[%row.maxlvl %]">[% row.deathlev %]/[% row.maxlvl %]</td>
templates/front.tt:<td class="numeric" data-sortkey="[% row.maxhp %]">[% row.hp %]/[% row.maxhp %]</td>
templates/front.tt:<span class="combono">[% IF game.dump %]<a href="[% game.dump %]">[% END %][% game.n %][% IF game.dump %]</a>[% END %]</span><span class="combo">[% game.role %]-[% game.race %]-[% game.gender %]-[% game.align %]</span>
templates/firstasc.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/firstasc.tt:  <meta charset="utf-8">
templates/firstasc.tt:  [% IF cnt_offset; SET cnt_offset = cnt_offset - 1; NEXT; END %]
templates/firstasc.tt:  [% IF !cnt_cols; LAST; ELSE; SET cnt_cols = cnt_cols - 1; END %]
templates/firstasc.tt:    [% IF cnt_offset; SET cnt_offset = cnt_offset - 1; NEXT; END %]
templates/firstasc.tt:    [% IF !cnt_cols; LAST; ELSE; SET cnt_cols = cnt_cols - 1; END %]
templates/firstasc.tt:      [% IF table.item(i).item(j).item(k) == -1 %]
templates/firstasc.tt:[% IF cnt_offset; SET cnt_offset = cnt_offset - 1; NEXT; END %]
templates/firstasc.tt:[% IF !cnt_cols; LAST; ELSE; SET cnt_cols = cnt_cols - 1; END %]
templates/firstasc.tt:<p style="line-height : 180%">
templates/streaks.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/streaks.tt:  <meta charset="utf-8" />
templates/streaks.tt:<td class="numeric"><span class="streak-open">[% row.wins %]</span></td>
templates/streaks.tt:<span class="combono">[% IF game.dump %]<a href="[% game.dump %]">[% END %][% game.n %][% IF game.dump %]</a>[% END %]</span><span class="combo">[% game.role %]-[% game.race %]-[% game.gender %]-[% game.align %]</span>
templates/player.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/player.tt:[%- USE percent = format("%0.1f%%") -%]
templates/player.tt:[%- USE zsc = format("%0.4f") -%]
templates/player.tt:[%- USE Dumper -%]
templates/player.tt:  <meta charset="utf-8" />
templates/player.tt:[% IF result_ascended.size -%]  
templates/player.tt:[% END -%]
templates/player.tt:<th>z-score</th>
templates/player.tt:[% IF games_first.dump -%]
templates/player.tt:[%- ELSE -%]
templates/player.tt:[%- END %]
templates/player.tt:[% IF games_last.dump -%]
templates/player.tt:[%- ELSE -%]
templates/player.tt:[%- END %]
templates/player.tt:[%- FOREACH acct IN lnk_accounts -%]
templates/player.tt:            <span class="streak-open">[% row.wins %]</span>
templates/player.tt:              <span class="combono"><a href="#asc[% game.n %]">[% game.n %]</a></span><span class="combo">[% game.role %]-[% game.race %]-[% game.gender %]-[% game.align %]</span> 
templates/player.tt:[% FOREACH role IN nh_roles -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH role IN nh_roles -%]
templates/player.tt:[% END -%]
templates/player.tt:[%- FOREACH role IN nh_roles -%]
templates/player.tt:[%- SET value = result_roles_all.item(role) -%]
templates/player.tt:[%- IF value; value = percent((value) / games_count_all * 100); END -%]
templates/player.tt:[% END -%]
templates/player.tt:[% IF result_ascended.size -%]
templates/player.tt:[% FOREACH role IN nh_roles -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH role IN nh_roles -%]
templates/player.tt:[%- SET value = result_roles_asc.item(role) -%]
templates/player.tt:[%- IF value; value = percent((value) / games_count_asc * 100); END -%]
templates/player.tt:[% END -%]
templates/player.tt:[% END -%]
templates/player.tt:<table class="bordered" style="margin-top : 1em; float : left; margin-right : 2em;">
templates/player.tt:[% FOREACH race IN nh_races -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH race IN nh_races -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH race IN nh_races -%]
templates/player.tt:[%- SET value = result_races_all.item(race) -%]
templates/player.tt:[%- IF value; value = percent((value) / games_count_all * 100); END -%]
templates/player.tt:[% END -%]
templates/player.tt:[% IF result_ascended.size -%]
templates/player.tt:[% FOREACH race IN nh_races -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH race IN nh_races -%]
templates/player.tt:[%- SET value = result_races_asc.item(race) -%]
templates/player.tt:[%- IF value; value = percent((value) / games_count_asc * 100); END -%]
templates/player.tt:[% END -%]
templates/player.tt:[% END -%]
templates/player.tt:<table class="bordered" style="margin-top : 1em;">
templates/player.tt:[% FOREACH align IN nh_aligns -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH align IN nh_aligns -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH align IN nh_aligns -%]
templates/player.tt:[%- SET value = result_aligns_all.item(align) -%]
templates/player.tt:[%- IF value; value = percent((value) / games_count_all * 100); END -%]
templates/player.tt:[% END -%]
templates/player.tt:[% IF result_ascended.size -%]
templates/player.tt:[% FOREACH align IN nh_aligns -%]
templates/player.tt:[% END -%]
templates/player.tt:[% FOREACH align IN nh_aligns -%]
templates/player.tt:[%- SET value = result_aligns_asc.item(align) -%]
templates/player.tt:[%- IF value; value = percent((value) / games_count_asc * 100); END -%]
templates/player.tt:[% END -%]
templates/player.tt:[% END -%]
templates/player.tt:<td class="numeric"><span class="streak-open">[% row.wins %]</span></td>
templates/player.tt:<span class="combono"><a href="#asc[% game.n %]">[% game.n %]</a></span><span class="combo">[% game.role %]-[% game.race %]-[% game.gender %]-[% game.align %]</span>
templates/player.tt:[% FOREACH row IN result_calendar -%]
templates/player.tt:[%- SET th = 0 -%]
templates/player.tt:[% FOREACH col IN row -%]
templates/player.tt:[%- IF th == 0 -%]
templates/player.tt:[% ELSIF th == 13 -%]
templates/player.tt:[% ELSE -%]
templates/player.tt:[% END -%]
templates/player.tt:[%- SET th = th + 1 -%]
templates/player.tt:[%- END -%]
templates/player.tt:[% END -%]
templates/player.tt:    === Z-SCORE ==========================================================
templates/player.tt:<h3>Z-score Breakdown</h3>
templates/player.tt:      [% FOREACH role IN z_roles -%]
templates/player.tt:      [% END -%]
templates/player.tt:          [% FOREACH role IN nh_roles -%]
templates/player.tt:        [% FOREACH role IN z_roles -%]
templates/tab_recent.tt:[%- IF NOT devnull -%]
templates/tab_recent.tt:[%- END -%]
templates/tab_recent.tt:[%- IF not name -%]
templates/tab_recent.tt:[%- END -%]
templates/tab_recent.tt:[%- IF datetick -%]
templates/tab_recent.tt:[%- END -%]
templates/tab_recent.tt:[%- IF NOT devnull -%]
templates/tab_recent.tt:[%- END -%]
templates/tab_recent.tt:[%- IF not name -%]
templates/tab_recent.tt:  [%- IF devnull; THEN; row.name = row.name_orig; END -%]
templates/tab_recent.tt:[%- END %]
templates/tab_recent.tt:  [%- IF devnull; THEN; row.gender = row.gender0; row.align = row.align0; END -%]
templates/tab_recent.tt:  <td>[% row.role %]-[% row.race %]-[% row.gender %]-[% row.align %]</td>
templates/tab_recent.tt:[% IF row.dump -%]
templates/tab_recent.tt:[%- ELSE -%]
templates/tab_recent.tt:[%- END %]
templates/zscore.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/zscore.tt:[%- USE percent = format("%0.1f%%") -%]
templates/zscore.tt:[%- USE zsc = format("%0.4f") -%]
templates/zscore.tt:  <meta charset="utf-8" />
templates/zscore.tt:  <title>Z-scores</title>
templates/zscore.tt:<h1>Z-scores</h1>
templates/zscore.tt:    [% SET n = 0; SET prev = -1 %]
templates/zscore.tt:<p>No z-scores for this variant</p>
templates/gametime.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/gametime.tt:  <meta charset="utf-8">
templates/gametime.tt:[%# ------ %]
templates/gametime.tt:[%# ------ %]
templates/gametime.tt:<div style="display : inline-block; margin-right : 2em;">
templates/gametime.tt:<h3>Sub-20K Wins</h3>
templates/gametime.tt:<div style="display : inline-block; margin-right : 2em;">
templates/gametime.tt:<h3>Sub-10K Wins</h3>
templates/gametime.tt:<div style="display : inline-block">
templates/gametime.tt:<h3>Sub-5K Wins</h3>
templates/conduct.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/conduct.tt:  <meta charset="utf-8">
templates/about.tt:[%- MACRO number(n) GET n.chunk(-3).join(',') -%]
templates/about.tt:  <meta charset="utf-8" />
templates/about.tt:[% FOREACH row IN logfiles -%]
templates/about.tt:[%- SET stale = "stale_hi" -%]
templates/about.tt:[%- IF row.lastchk_30d; SET stale = "stale_mid"; END -%]
templates/about.tt:[%- IF row.lastchk_1d; SET stale = "stale_low"; END -%]
templates/about.tt:[%- IF row.lastchk_1h; SET stale = "fresh"; END -%]
templates/about.tt:[%- IF row.static; SET stale = "static"; END -%]
templates/about.tt:[%- SET entryage = "stale_hi" -%]
templates/about.tt:[%- IF row.lastentry_30d; SET entryage = "stale_mid"; END -%]
templates/about.tt:[%- IF row.lastentry_7d; SET entryage = "stale_low"; END -%]
templates/about.tt:[%- IF row.lastentry_1d; SET entryage = "fresh"; END -%]
templates/about.tt:[%- IF row.static; SET entryage = "static"; END -%]
nhdb-feeder.pl:# (c) 2013-2018 Borek Lupomesky
nhdb-feeder.pl:# This program scrapes logs from pre-defined NetHack servers and inserts
nhdb-feeder.pl:#--- pragmas ----------------------------------------------------------------
nhdb-feeder.pl:#--- external modules -------------------------------------------------------
nhdb-feeder.pl:#--- internal modules -------------------------------------------------------
nhdb-feeder.pl:#--- additional perl runtime setup ------------------------------------------
nhdb-feeder.pl:my $lockfile = '/tmp/nhdb-feeder.lock';
nhdb-feeder.pl:my %translations;               # name-to-name translations
nhdb-feeder.pl:my $nhdb = NHdb::Config->instance;
nhdb-feeder.pl:  #--- there are two field separators in use: comma and horizontal tab;
nhdb-feeder.pl:  #--- we use simple heuristics to find out the one that is used for given
nhdb-feeder.pl:  #--- xlogfile row
nhdb-feeder.pl:  #--- split keys and values
nhdb-feeder.pl:  #--- if this is enabled for a source (through "logfiles.options"), check
nhdb-feeder.pl:  #--- whether base64 fields exist and decode them
nhdb-feeder.pl:  if(grep(/^base64xlog$/, @{$log->{'options'}})) {
nhdb-feeder.pl:  #--- finish returning hashref
nhdb-feeder.pl:# --variant, --server and --logid command-line parameters.
nhdb-feeder.pl:  #--- arguments
nhdb-feeder.pl:  #--- other variables
nhdb-feeder.pl:  #--- variants
nhdb-feeder.pl:  #--- servers
nhdb-feeder.pl:  #--- logfile ids
nhdb-feeder.pl:  #--- assemble the final query
nhdb-feeder.pl:# the --oper and --static options. This function assumes that at least one
nhdb-feeder.pl:  #--- arguments
nhdb-feeder.pl:  #--- other init
nhdb-feeder.pl:  $logger->info('Requested oper/static flag change');
nhdb-feeder.pl:    $logger->info('Variants: ' . join(',', @$cmd_variant));
nhdb-feeder.pl:    $logger->info('Servers: ' . join(',', @$cmd_server));
nhdb-feeder.pl:    $logger->info('Log ids: ' . join(',', @$cmd_logid));
nhdb-feeder.pl:  #--- on what entries we are going to operate
nhdb-feeder.pl:  #--- what are we going to do
nhdb-feeder.pl:  $logger->info('Operation: ', join(', ', @set));
nhdb-feeder.pl:  #--- assemble the query
nhdb-feeder.pl:  #--- perform the query
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  my $r = $dbh->do($qry, undef, @arg);
nhdb-feeder.pl:    $logger->fatal('Database error occured');
nhdb-feeder.pl:    $logger->fatal($dbh->errstr());
nhdb-feeder.pl:  $logger->info(sprintf('%d rows affected', $r));
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- create new streak entry
nhdb-feeder.pl:  my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:  my $r = $sth->execute($logfiles_i, $name, $name_orig);
nhdb-feeder.pl:    $logger->fatal(
nhdb-feeder.pl:        $sth->errstr()
nhdb-feeder.pl:    return $sth->errstr();
nhdb-feeder.pl:  #--- retrieve streak id
nhdb-feeder.pl:  my ($streaks_i) = $sth->fetchrow_array();
nhdb-feeder.pl:  $sth->finish();
nhdb-feeder.pl:  $logger->debug(
nhdb-feeder.pl:  #--- add the game to the new streak
nhdb-feeder.pl:  #--- return
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- create mapping entry
nhdb-feeder.pl:  my $r = $dbh->do($qry, undef, $rowid, $streaks_i);
nhdb-feeder.pl:    $logger->fatal(
nhdb-feeder.pl:        $streaks_i, $rowid, $dbh->errstr()
nhdb-feeder.pl:    return $dbh->errstr();
nhdb-feeder.pl:  $logger->debug(
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- close streak entity and get its current state
nhdb-feeder.pl:  my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:  my $r = $sth->execute($streaks_i);
nhdb-feeder.pl:    $logger->fatal(
nhdb-feeder.pl:        $streaks_i, $dbh->errstr()
nhdb-feeder.pl:    return $sth->errstr();
nhdb-feeder.pl:  $logger->debug(sprintf('Closed streak %d', $streaks_i));
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:  my $r = $sth->execute($logfiles_i);
nhdb-feeder.pl:    $logger->error(
nhdb-feeder.pl:        $logfiles_i, $dbh->errstr()
nhdb-feeder.pl:    return $sth->errstr();
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:  my $r = $sth->execute($streaks_i);
nhdb-feeder.pl:    $logger->fatal(
nhdb-feeder.pl:        $streaks_i, $dbh->errstr()
nhdb-feeder.pl:    return $sth->errstr();
nhdb-feeder.pl:  my $result = $sth->fetchrow_hashref();
nhdb-feeder.pl:  $sth->finish();
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:  #--- arguments
nhdb-feeder.pl:  #--- other init
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- db query
nhdb-feeder.pl:  my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:  my $r = $sth->execute($logfiles_i, $name);
nhdb-feeder.pl:    $logger->fatal(
nhdb-feeder.pl:        $logfiles_i, $name, $dbh->errstr()
nhdb-feeder.pl:    return $sth->errstr();
nhdb-feeder.pl:  my $streaks_i = $sth->fetchrow_array();
nhdb-feeder.pl:  $sth->finish();
nhdb-feeder.pl:  $logger->debug(
nhdb-feeder.pl:      'Pre-existing streak %d for (%d,%s) found',
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:  #--- arguments
nhdb-feeder.pl:  #--- other variables
nhdb-feeder.pl:  # value; b) sub-array of 1. SQL expression that contains single placeholder
nhdb-feeder.pl:  # 2. simple scalar value. -- this is needed to be able to use placeholders
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- reject too old log entries without necessary info
nhdb-feeder.pl:  return undef unless $nhdb->require_fields(keys %$l);
nhdb-feeder.pl:  #--- reject wizmode games, paxed test games
nhdb-feeder.pl:  return undef if $nhdb->reject_name($l->{'name'});
nhdb-feeder.pl:  #--- reject "special" modes of NH4 and its kin
nhdb-feeder.pl:  #--- Fourk challenge mode is okay, though
nhdb-feeder.pl:    exists $l->{'mode'} &&
nhdb-feeder.pl:    !($l->{'mode'} eq 'normal' || $l->{'mode'} eq 'challenge')
nhdb-feeder.pl:  #--- reject entries with empty name
nhdb-feeder.pl:  if(!exists $l->{'name'} || !$l->{'name'}) { return undef; }
nhdb-feeder.pl:  #--- death (reason)
nhdb-feeder.pl:  my $death = $l->{'death'};
nhdb-feeder.pl:  $death =~ tr[\x{9}\x{A}\x{D}\x{20}-\x{D7FF}\x{E000}-\x{FFFD}\x{10000}-\x{10FFFF}][]cd;
nhdb-feeder.pl:  #--- ascended flag
nhdb-feeder.pl:  $l->{'ascended'} = $death =~ /^(ascended|defied the gods)\b/ ? 1 : 0;
nhdb-feeder.pl:  push(@values, $l->{'ascended'} ? 'TRUE' : 'FALSE');
nhdb-feeder.pl:  #--- dNetHack combo mangling workaround
nhdb-feeder.pl:  if($variant eq 'dnh' && $l->{'ascended'}) {
nhdb-feeder.pl:    ($l->{'role'}, $l->{'race'})
nhdb-feeder.pl:    = $nh->variant('dnh')->dnethack_map($l->{'role'}, $l->{'race'});
nhdb-feeder.pl:  #--- regular fields
nhdb-feeder.pl:  for my $k ($nhdb->regular_fields()) {
nhdb-feeder.pl:    if(exists $l->{$k}) {
nhdb-feeder.pl:      push(@values, $l->{$k});
nhdb-feeder.pl:  #--- name (before translation)
nhdb-feeder.pl:  push(@values, $l->{'name'});
nhdb-feeder.pl:  $l->{'name_orig'} = $l->{'name'};
nhdb-feeder.pl:  #--- name
nhdb-feeder.pl:  if(exists($translations{$server}{$l->{'name'}})) {
nhdb-feeder.pl:    $l->{'name'} = $translations{$server}{$l->{'name'}};
nhdb-feeder.pl:  push(@values, $l->{'name'});
nhdb-feeder.pl:  #--- logfiles_i
nhdb-feeder.pl:  #--- line number
nhdb-feeder.pl:  #--- conduct
nhdb-feeder.pl:  if($l->{'conduct'}) {
nhdb-feeder.pl:    push(@values, eval($l->{'conduct'}));
nhdb-feeder.pl:  #--- achieve
nhdb-feeder.pl:  if(exists $l->{'achieve'}) {
nhdb-feeder.pl:    push(@values, eval($l->{'achieve'}));
nhdb-feeder.pl:  #--- start time
nhdb-feeder.pl:  if(exists $l->{'starttime'}) {
nhdb-feeder.pl:    push(@values, [ q{timestamp with time zone 'epoch' + ? * interval '1 second'}, $l->{'starttime'} ]) ;
nhdb-feeder.pl:    push(@values, $l->{'starttime'});
nhdb-feeder.pl:  #--- end time
nhdb-feeder.pl:  if(exists $l->{'endtime'}) {
nhdb-feeder.pl:    push(@values, [ q{timestamp with time zone 'epoch' + ? * interval '1 second'}, $l->{'endtime'} ]);
nhdb-feeder.pl:    push(@values, $l->{'endtime'});
nhdb-feeder.pl:  #--- birth date
nhdb-feeder.pl:  if(exists $l->{'birthdate'} && !exists $l->{'starttime'}) {
nhdb-feeder.pl:    push(@values, $l->{'birthdate'});
nhdb-feeder.pl:    push(@values, $l->{'birthdate'});
nhdb-feeder.pl:  #--- death date
nhdb-feeder.pl:  if(exists $l->{'deathdate'} && !exists $l->{'endtime'}) {
nhdb-feeder.pl:    push(@values, $l->{'deathdate'});
nhdb-feeder.pl:    push(@values, $l->{'deathdate'});
nhdb-feeder.pl:  #--- quit flag (escaped also counts)
nhdb-feeder.pl:  #--- scummed flag
nhdb-feeder.pl:  if($flag_quit eq 'TRUE' && $l->{'points'} < 1000) {
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:      join(',', map { ref() ? $_->[0] : '?' } @values)
nhdb-feeder.pl:    [ map { ref() ? $_->[1] : $_ } @values ]
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- write updated variants
nhdb-feeder.pl:      $re = $dbh->do(
nhdb-feeder.pl:        return $dbh->errstr();
nhdb-feeder.pl:        $re = $dbh->do(
nhdb-feeder.pl:        if(!$re) { return $dbh->errstr(); }
nhdb-feeder.pl:  #--- write update player names
nhdb-feeder.pl:    for my $var (keys %{$update_name->{$name}}, 'all') {
nhdb-feeder.pl:      $re = $dbh->do(
nhdb-feeder.pl:      if(!$re) { return $dbh->errstr(); }
nhdb-feeder.pl:        $re = $dbh->do(
nhdb-feeder.pl:          return $dbh->errstr();
nhdb-feeder.pl:  #--- finish successfully
nhdb-feeder.pl:  #--- arguments
nhdb-feeder.pl:  #--- other variables
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- init logging
nhdb-feeder.pl:  $logger->info('Requested database purge');
nhdb-feeder.pl:    $logger->info('Variants: ' . join(',', @$variants));
nhdb-feeder.pl:    $logger->info('Servers: ' . join(',', @$servers));
nhdb-feeder.pl:    $logger->info('Log ids: ' . join(',', @$logids));
nhdb-feeder.pl:  #--- get list of logfiles we will be operating on
nhdb-feeder.pl:  my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:  my $r = $sth->execute(@arg);
nhdb-feeder.pl:    $logger->fatal(
nhdb-feeder.pl:      sprintf('Failed to get list of logfiles (%s)', $sth->errstr())
nhdb-feeder.pl:  while(my $s = $sth->fetchrow_hashref()) {
nhdb-feeder.pl:    $logger->fatal("No matching logfiles");
nhdb-feeder.pl:    $logger->info(sprintf('%d logfiles to be purged', scalar(@logfiles)));
nhdb-feeder.pl:  #--- iterate over logfiles
nhdb-feeder.pl:    my ($srv, $var) = ($log->{'server'}, $log->{'variant'});
nhdb-feeder.pl:    my $logfiles_i = $log->{'logfiles_i'};
nhdb-feeder.pl:    $logger->info("[$srv/$var] ", $log->{'descr'});
nhdb-feeder.pl:  #--- eval begin
nhdb-feeder.pl:  #--- start transaction
nhdb-feeder.pl:      $r = $dbh->begin_work();
nhdb-feeder.pl:        $logger->fatal(
nhdb-feeder.pl:            $srv, $var, $dbh->errstr()
nhdb-feeder.pl:  #--- delete the games
nhdb-feeder.pl:      $logger->info("[$srv/$var] Deleting from games");
nhdb-feeder.pl:      $r = $dbh->do('DELETE FROM games WHERE logfiles_i = ?', undef, $logfiles_i);
nhdb-feeder.pl:        $logger->fatal(
nhdb-feeder.pl:            $srv, $var, $dbh->errstr()
nhdb-feeder.pl:        $logger->info(
nhdb-feeder.pl:  #--- reset 'fpos' field in 'logfiles' table
nhdb-feeder.pl:      $r = $dbh->do(
nhdb-feeder.pl:        $logger->fatal(
nhdb-feeder.pl:  #--- eval end
nhdb-feeder.pl:      $r = $dbh->commit();
nhdb-feeder.pl:        $logger->fatal(
nhdb-feeder.pl:            $srv, $var, $dbh->errstr()
nhdb-feeder.pl:        $logger->info("[$srv/$var] Transaction commited");
nhdb-feeder.pl:      $r = $dbh->rollback();
nhdb-feeder.pl:        $logger->fatal(
nhdb-feeder.pl:            $srv, $var, $dbh->errstr()
nhdb-feeder.pl:        $logger->info("[$srv/$var] Transaction aborted");
nhdb-feeder.pl:  #--- end of iteration over logfiles
nhdb-feeder.pl:# Function for listing/adding/removing player name mappings using the --pmap
nhdb-feeder.pl:# options (--pmap-list, --pmap-add, --pmap-remove).
nhdb-feeder.pl:  #--- init
nhdb-feeder.pl:  my $dbh = $db->handle();
nhdb-feeder.pl:  #--- eval loop
nhdb-feeder.pl:  #--- listing all configured mappings
nhdb-feeder.pl:      $logger->info('Listing configured player name mappings');
nhdb-feeder.pl:      my $sth = $dbh->prepare('SELECT * FROM translations ORDER BY name_to');
nhdb-feeder.pl:      $r = $sth->execute();
nhdb-feeder.pl:        die 'Failed to query database (' . $sth->errstr() . ") \n";
nhdb-feeder.pl:        $logger->info('source               | destination');
nhdb-feeder.pl:        $logger->info('-' x (20+16+3));
nhdb-feeder.pl:        while(my $row = $sth->fetchrow_hashref()) {
nhdb-feeder.pl:          $logger->info(
nhdb-feeder.pl:              "%-20s | %-16s\n",
nhdb-feeder.pl:              $row->{'server'} . '/' . $row->{'name_from'},
nhdb-feeder.pl:              $row->{'name_to'}
nhdb-feeder.pl:        $logger->info('-' x (20+16+3));
nhdb-feeder.pl:        $logger->info(
nhdb-feeder.pl:  #--- start transaction
nhdb-feeder.pl:    $r = $dbh->begin_work();
nhdb-feeder.pl:      die sprintf("Cannot begin database transaction (%s)\n", $dbh->errstr());
nhdb-feeder.pl:  #--- loop over arguments and create update plan
nhdb-feeder.pl:        (?<src>[a-zA-Z0-9]+)         # 1. source (server-specific) name
nhdb-feeder.pl:        (?<srv>[a-zA-Z0-9]{3})       # 2. server id
nhdb-feeder.pl:          (?<dst>[a-zA-Z0-9]+)       # 3. destination (aggregate) name
nhdb-feeder.pl:  #--- perform removals
nhdb-feeder.pl:      $r = $dbh->do(
nhdb-feeder.pl:        undef, $row->{'srv'}, $row->{'src'}
nhdb-feeder.pl:        $r = $dbh->do(
nhdb-feeder.pl:          undef, $row->{'src'}, $row->{'srv'}
nhdb-feeder.pl:          $s = $dbh->do(
nhdb-feeder.pl:            undef, $row->{'src'}, $row->{'srv'}
nhdb-feeder.pl:        die sprintf "Failed to update database (%s)\n", $dbh->errstr();
nhdb-feeder.pl:      $logger->info(sprintf(
nhdb-feeder.pl:        $row->{'srv'}, $row->{'src'}, $r, $s
nhdb-feeder.pl:  #--- perform additions
nhdb-feeder.pl:      $r = $dbh->do(
nhdb-feeder.pl:        undef, $row->{'srv'}, $row->{'src'}, $row->{'dst'}
nhdb-feeder.pl:        $r = $dbh->do(
nhdb-feeder.pl:          undef, $row->{'dst'}, $row->{'src'}, $row->{'srv'}
nhdb-feeder.pl:          $s = $dbh->do(
nhdb-feeder.pl:            undef, $row->{'dst'}, $row->{'src'}, $row->{'srv'}
nhdb-feeder.pl:        die sprintf "Failed to update database (%s)\n", $dbh->errstr();
nhdb-feeder.pl:      $logger->info(sprintf(
nhdb-feeder.pl:        $row->{'srv'}, $row->{'src'}, $row->{'dst'}, $r, $s
nhdb-feeder.pl:  #--- eval end
nhdb-feeder.pl:    $logger->error($err);
nhdb-feeder.pl:      $r = $dbh->rollback();
nhdb-feeder.pl:        $logger->error(
nhdb-feeder.pl:          sprintf('Failed to abort transaction (%s)', $dbh->errstr())
nhdb-feeder.pl:        $err = $err . sprintf(', transaction not aborted (%s)', $dbh->errstr());
nhdb-feeder.pl:        $logger->error('Transaction aborted, no changes made');
nhdb-feeder.pl:  #--- commit transaction
nhdb-feeder.pl:    $r = $dbh->commit();
nhdb-feeder.pl:        'Failed to commit database transaction (%s)', $dbh->errstr()
nhdb-feeder.pl:    $logger->info('Changes commited');
nhdb-feeder.pl:  #--- finish successfully
nhdb-feeder.pl:#--- initialize logging
nhdb-feeder.pl:Log::Log4perl->init('cfg/logging.conf');
nhdb-feeder.pl:#--- title
nhdb-feeder.pl:$logger->info('NetHack Scoreboard / Feeder');
nhdb-feeder.pl:$logger->info('(c) 2013-17 Borek Lupomesky');
nhdb-feeder.pl:$logger->info('---');
nhdb-feeder.pl:#--- process commandline options
nhdb-feeder.pl:my $cmd = NHdb::Feeder::Cmdline->instance(lockfile => $lockfile);
nhdb-feeder.pl:#--- lock file check/open
nhdb-feeder.pl:  $cmd->lock;
nhdb-feeder.pl:  $logger->warn($_);
nhdb-feeder.pl:#--- connect to database
nhdb-feeder.pl:$db = NHdb::Db->new(id => 'nhdbfeeder', config => $nhdb);
nhdb-feeder.pl:my $dbh = $db->handle();
nhdb-feeder.pl:#--- process --oper and --static options
nhdb-feeder.pl:if(defined($cmd->operational()) || defined($cmd->static())) {
nhdb-feeder.pl:    $cmd->variants(),
nhdb-feeder.pl:    $cmd->servers(),
nhdb-feeder.pl:    $cmd->logid(),
nhdb-feeder.pl:    $cmd->operational(),
nhdb-feeder.pl:    $cmd->static()
nhdb-feeder.pl:#--- process --pmap options
nhdb-feeder.pl:if($cmd->pmap_list()) {
nhdb-feeder.pl:if($cmd->pmap_add() || $cmd->pmap_remove()) {
nhdb-feeder.pl:    grep { /^[a-zA-Z0-9]+\/[a-zA-Z0-9]+=[a-zA-Z0-9]+$/ } @{$cmd->pmap_add()}
nhdb-feeder.pl:    if $cmd->pmap_add();
nhdb-feeder.pl:    grep { /^[a-zA-Z0-9]+\/[a-zA-Z0-9]+$/ } @{$cmd->pmap_remove()}
nhdb-feeder.pl:    if $cmd->pmap_remove();
nhdb-feeder.pl:    $logger->fatal('No valid maps');
nhdb-feeder.pl:#--- get list of logfiles to process
nhdb-feeder.pl:push(@qry, q{WHERE oper = 't'}) unless $cmd->show_logfiles();
nhdb-feeder.pl:my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:my $r = $sth->execute();
nhdb-feeder.pl:  die 'Database query failed (' . $sth->errstr() . ')';
nhdb-feeder.pl:while(my $s = $sth->fetchrow_hashref()) {
nhdb-feeder.pl:$logger->info(
nhdb-feeder.pl:#--- display logfiles, if requested
nhdb-feeder.pl:if($cmd->show_logfiles()) {
nhdb-feeder.pl:  $logger->info('Displaying configured logfiles (--logfiles option)');
nhdb-feeder.pl:  $logger->info('');
nhdb-feeder.pl:  $logger->info('* disabled sources, + static sources');
nhdb-feeder.pl:  $logger->info('');
nhdb-feeder.pl:  $logger->info('rowid  srv var descr');
nhdb-feeder.pl:  $logger->info('------ --- --- ' . '-' x 42);
nhdb-feeder.pl:    if($log->{'static'}) { $s = '+'; }
nhdb-feeder.pl:    if(!$log->{'oper'}) { $s = '*'; }
nhdb-feeder.pl:    $logger->info(
nhdb-feeder.pl:        "%5d%1s %-3s %-3s %s\n",
nhdb-feeder.pl:        $log->{'logfiles_i'},
nhdb-feeder.pl:        $log->{'server'},
nhdb-feeder.pl:        $log->{'variant'},
nhdb-feeder.pl:        substr($log->{'descr'}, 0, 48)
nhdb-feeder.pl:#--- database purge
nhdb-feeder.pl:if($cmd->purge()) {
nhdb-feeder.pl:  sql_purge_database($cmd->variants(), $cmd->servers(), $cmd->logid());
nhdb-feeder.pl:#--- load list of translations
nhdb-feeder.pl:$sth = $dbh->prepare($qry);
nhdb-feeder.pl:$r = $sth->execute();
nhdb-feeder.pl:  die 'Database query failed (' . $sth->errstr() . ')';
nhdb-feeder.pl:while(my @a = $sth->fetchrow_array()) {
nhdb-feeder.pl:$logger->info(
nhdb-feeder.pl:#--- check update table
nhdb-feeder.pl:$logger->info('Checking update table');
nhdb-feeder.pl:my $sth = $dbh->prepare('SELECT count(*) FROM update');
nhdb-feeder.pl:my $r = $sth->execute();
nhdb-feeder.pl:  die sprintf("Cannot count update table (%s)", $sth->errstr());
nhdb-feeder.pl:my ($cnt_update) = $sth->fetchrow_array();
nhdb-feeder.pl:$sth->finish();
nhdb-feeder.pl:  $logger->info('No entries in the update table');
nhdb-feeder.pl:  $logger->info('Initializing update table, step 1');
nhdb-feeder.pl:  $r = $dbh->do(
nhdb-feeder.pl:    die sprintf("Failed to initialize the update table (%s)", $sth->errstr());
nhdb-feeder.pl:    $logger->info(sprintf('Update table initialized with %d entries (step 1)', $r));
nhdb-feeder.pl:  $logger->info('Initializing update table, step 2');
nhdb-feeder.pl:  $r = $dbh->do(
nhdb-feeder.pl:    die sprintf("Failed to initialize the update table (%s)", $sth->errstr());
nhdb-feeder.pl:      $logger->info(sprintf('Update table initialized with %d entries (step 2)', $r));
nhdb-feeder.pl:  $logger->info(sprintf('Update table has %d entries', $cnt_update));
nhdb-feeder.pl:#--- iterate over logfiles
nhdb-feeder.pl:  my $logfiles_i = $log->{'logfiles_i'};
nhdb-feeder.pl:  my $lbl = sprintf('[%s/%s] ', $log->{'variant'}, $log->{'server'});
nhdb-feeder.pl:  #--- user selection processing
nhdb-feeder.pl:    @{$cmd->variants()} &&
nhdb-feeder.pl:    !grep { $log->{'variant'} eq lc($_) } @{$cmd->variants()};
nhdb-feeder.pl:    scalar(@{$cmd->servers()}) &&
nhdb-feeder.pl:    !grep { $log->{'server'} eq lc($_) } @{$cmd->servers()};
nhdb-feeder.pl:    $cmd->logid() &&
nhdb-feeder.pl:    $log->{'logfiles_i'} != $cmd->logid();
nhdb-feeder.pl:  eval { # <--- eval starts here -------------------------------------------
nhdb-feeder.pl:    #--- prepare, print info
nhdb-feeder.pl:      $nhdb->config()->{'logs'}{'localpath'},
nhdb-feeder.pl:      $log->{'localfile'}
nhdb-feeder.pl:    my $fpos = $log->{'fpos'};
nhdb-feeder.pl:    $fsize[0] = -s $localfile;
nhdb-feeder.pl:    $logger->info('---');
nhdb-feeder.pl:    $logger->info($lbl, 'Processing started');
nhdb-feeder.pl:    $logger->info($lbl, 'Local file is ', $localfile);
nhdb-feeder.pl:    $logger->info($lbl, 'Logfile URL is ', $log->{'logurl'} ? $log->{'logurl'} : 'N/A');
nhdb-feeder.pl:    #--- retrieve file
nhdb-feeder.pl:    if($log->{'static'}) {
nhdb-feeder.pl:      $logger->info($lbl, 'Static logfile, skipping retrieval');
nhdb-feeder.pl:    } elsif(!$log->{'logurl'}) {
nhdb-feeder.pl:      $logger->warn($lbl, 'Log URL not defined, skipping retrieval');
nhdb-feeder.pl:      $logger->info($lbl, 'Getting logfile from the server');
nhdb-feeder.pl:        sprintf($nhdb->config()->{'wget'}, $localfile, $log->{'logurl'})
nhdb-feeder.pl:      if($r) { $logger->warn($lbl, 'Failed to get the logfile'); die; }
nhdb-feeder.pl:      $fsize[1] = -s $localfile;
nhdb-feeder.pl:      $logger->info($lbl, sprintf('Logfile retrieved successfully, got %d bytes', $fsize[1] - $fsize[0]));
nhdb-feeder.pl:        $log->{'fpos'}
nhdb-feeder.pl:        && ($fsize[1] - $fsize[0] < 1)
nhdb-feeder.pl:        && ($fsize[0] - $log->{'fpos'} < 1)
nhdb-feeder.pl:        $logger->info($lbl, 'No new data, skipping further processing');
nhdb-feeder.pl:        $dbh->do(
nhdb-feeder.pl:    #--- open the file
nhdb-feeder.pl:      $logger->error($lbl, 'Failed to open local file ', $localfile);
nhdb-feeder.pl:    #--- seek into the file (if position is known)
nhdb-feeder.pl:      $logger->info($lbl, sprintf('Seeking to %d', $fpos));
nhdb-feeder.pl:        $logger->error($lbl, sprintf('Failed to seek to $fpos', $fpos));
nhdb-feeder.pl:    #--- set timezone
nhdb-feeder.pl:    $logger->info($lbl, 'Setting time zone to ', $log->{'tz'});
nhdb-feeder.pl:    $r = $dbh->do(sprintf(q{SET TIME ZONE '%s'}, $log->{'tz'}));
nhdb-feeder.pl:      $logger->error($lbl, 'Failed to set time zone');
nhdb-feeder.pl:    #--- begin transaction
nhdb-feeder.pl:    $logger->info($lbl, 'Starting database transaction');
nhdb-feeder.pl:    $r = $dbh->begin_work();
nhdb-feeder.pl:      $logger->info($lbl, 'Failed to start database transaction');
nhdb-feeder.pl:    #--- now read content of the file
nhdb-feeder.pl:    $devnull = grep(/^devnull$/, @{$log->{'options'}});
nhdb-feeder.pl:    $logger->info($lbl, 'Processing file ', $localfile);
nhdb-feeder.pl:    #--- devnull logfiles are slightly modified by having a server id
nhdb-feeder.pl:    #--- prepended to the usual xlogfile line
nhdb-feeder.pl:    #--- parse log
nhdb-feeder.pl:    #--- insert row into database
nhdb-feeder.pl:        $log->{'lines'} + $lc,
nhdb-feeder.pl:        $log->{'server'},
nhdb-feeder.pl:        $log->{'variant'},
nhdb-feeder.pl:        my $sth = $dbh->prepare($qry);
nhdb-feeder.pl:        $r = $sth->execute(@$values);
nhdb-feeder.pl:          $logger->error($lbl, 'Failure during inserting new records');
nhdb-feeder.pl:          $logger->error($lbl, sql_show_query($qry, $values));
nhdb-feeder.pl:          $logger->error($lbl, $sth->errstr());
nhdb-feeder.pl:        ($rowid) = $sth->fetchrow_array();
nhdb-feeder.pl:        $sth->finish();
nhdb-feeder.pl:    #--- mark updates
nhdb-feeder.pl:        $update_variant{$log->{'variant'}} = 1;
nhdb-feeder.pl:        $update_name{$pl->{'name'}}{$log->{'variant'}} = 1;
nhdb-feeder.pl:    #-------------------------------------------------------------------------
nhdb-feeder.pl:    #--- streak processing starts here ---------------------------------------
nhdb-feeder.pl:    #-------------------------------------------------------------------------
nhdb-feeder.pl:    #--- initialize streak status for name
nhdb-feeder.pl:        if(!exists($streak_open{$logfiles_i}{$pl->{'name'}})) {
nhdb-feeder.pl:          $r = sql_streak_find($logfiles_i, $pl->{'name'});
nhdb-feeder.pl:          $streak_open{$logfiles_i}{$pl->{'name'}} = $r->[0];
nhdb-feeder.pl:    #--- game is ASCENDED
nhdb-feeder.pl:        if($pl->{'ascended'}) {
nhdb-feeder.pl:    #--- game is ASCENDED / streak is NOT OPEN
nhdb-feeder.pl:          if(!$streak_open{$logfiles_i}{$pl->{'name'}}) {
nhdb-feeder.pl:              $pl->{'name'},
nhdb-feeder.pl:              $pl->{'name_orig'},
nhdb-feeder.pl:            $streak_open{$logfiles_i}{$pl->{'name'}} = $streaks_i->[0]
nhdb-feeder.pl:    #--- game is ASCENDED / streak is OPEN
nhdb-feeder.pl:              $streak_open{$logfiles_i}{$pl->{'name'}}
nhdb-feeder.pl:                $streak_open{$logfiles_i}{$pl->{'name'}}, $last_game
nhdb-feeder.pl:              $last_game->{'endtime_raw'}
nhdb-feeder.pl:              && $pl->{'starttime'}
nhdb-feeder.pl:              && $last_game->{'endtime_raw'} >= $pl->{'starttime'}
nhdb-feeder.pl:              $logger->info($lbl,
nhdb-feeder.pl:                sprintf('Closing overlapping streak %d', $streak_open{$logfiles_i}{$pl->{'name'}})
nhdb-feeder.pl:                $streak_open{$logfiles_i}{$pl->{'name'}}
nhdb-feeder.pl:                $pl->{'name'},
nhdb-feeder.pl:                $pl->{'name_orig'},
nhdb-feeder.pl:              $streak_open{$logfiles_i}{$pl->{'name'}} = $r->[0];
nhdb-feeder.pl:                $streak_open{$logfiles_i}{$pl->{'name'}},
nhdb-feeder.pl:    #--- game is not ASCENDED
nhdb-feeder.pl:    #--- game is not ASCENDED / streak is OPEN
nhdb-feeder.pl:          if($streak_open{$logfiles_i}{$pl->{'name'}}) {
nhdb-feeder.pl:              $streak_open{$logfiles_i}{$pl->{'name'}}
nhdb-feeder.pl:            $streak_open{$logfiles_i}{$pl->{'name'}} = undef;
nhdb-feeder.pl:    #--- display progress info
nhdb-feeder.pl:      if((time() - $tm) > 5) {
nhdb-feeder.pl:        $logger->info($lbl,
nhdb-feeder.pl:          sprintf('Processing (%d lines, %d l/sec)', $lc, ($lc-$ll)/5 )
nhdb-feeder.pl:    $logger->info($lbl,
nhdb-feeder.pl:    #--- close streak for 'static' sources
nhdb-feeder.pl:    if($log->{'static'}) {
nhdb-feeder.pl:        $logger->error($lbl, q{Failed to close all streaks});
nhdb-feeder.pl:      if($re->[0]) {
nhdb-feeder.pl:        $logger->info($lbl, sprintf('Closed %d streak(s)', $re->[0]));
nhdb-feeder.pl:    #--- write update info
nhdb-feeder.pl:    #--- update database with new position in the file
nhdb-feeder.pl:    if($log->{'static'}) { push(@logupdate, 'oper = false'); }
nhdb-feeder.pl:    $sth = $dbh->prepare($qry);
nhdb-feeder.pl:    $r = $sth->execute(
nhdb-feeder.pl:      $log->{'lines'} + $lc,
nhdb-feeder.pl:      $log->{'logfiles_i'}
nhdb-feeder.pl:      $logger->error($lbl, q{Failed to update table 'servers'});
nhdb-feeder.pl:    #--- commit transaction
nhdb-feeder.pl:    $r = $dbh->commit();
nhdb-feeder.pl:      $logger->error($lbl, 'Failed to commit transaction');
nhdb-feeder.pl:    $logger->info($lbl, 'Transaction commited');
nhdb-feeder.pl:  }; # <--- eval ends here -------------------------------------------------
nhdb-feeder.pl:  #--- log exception message, if any
nhdb-feeder.pl:    $logger->warn($lbl, 'Eval ended with error: ', $@);
nhdb-feeder.pl:  #--- rollback if needed
nhdb-feeder.pl:    $logger->warn($lbl, 'Transaction rollback');
nhdb-feeder.pl:    $dbh->rollback();
nhdb-feeder.pl:  #--- finish
nhdb-feeder.pl:  $logger->info($lbl, 'Processing finished');
nhdb-feeder.pl:#--- release lock file
nhdb-feeder.pl:$cmd->unlock;
schema/translations.sql:----------------------------------------------------------------------------
schema/translations.sql:--- tables 
schema/translations.sql:----------------------------------------------------------------------------
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:--- sequences
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:--- tables
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:--- views
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:    to_char(endtime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS endtime_fmt,
schema/games.sql:    to_char(endtime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS endtime_fmt,
schema/games.sql:    to_char(endtime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS endtime_fmt,
schema/games.sql:    to_char(endtime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS endtime_fmt,
schema/games.sql:    to_char(endtime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS endtime_fmt,
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:--- functions
schema/games.sql:----------------------------------------------------------------------------
schema/games.sql:-- Function that counts bit in an integer. Used to get number of conducts
schema/games.sql:-- as these are represented by bitfield.
schema/games.sql:      amount := amount + ((i >> (n-1)) & 1);
schema/games.sql:-- This function returns list of combos with info about player who
schema/games.sql:-- was the first to achieve a win for given combo. This function
schema/games.sql:-- is a wrapper for a query that can't be made into a view (because
schema/games.sql:-- we need to be able to supply a parameter to it)
schema/games.sql:--
schema/games.sql:-- IMPORTANT: The single-query solution given below is flawed;
schema/games.sql:-- it is possible that the wrong game is returned that has
schema/games.sql:-- the same (endtime, role, race, align0) as the correct one.
schema/games.sql:  to_char(g.starttime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS starttime_fmt,
schema/games.sql:  to_char(g.endtime AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI') AS endtime_fmt,
schema/update.sql:-- update table
schema/update.sql:-- """"""""""""
schema/update.sql:-- This table has dual purpose:
schema/update.sql:--
schema/update.sql:-- The first purpose is to track "objects" that need to be updated
schema/update.sql:-- to optimize stats generation; the feeder component sets the
schema/update.sql:-- update flag on when it inserts rows into games table; the
schema/update.sql:-- stats generator then uses the info to update relevant pages
schema/update.sql:-- and after doing so it clears the flags.
schema/update.sql:--
schema/update.sql:-- The second use is to track (name, variant) pairs' existence; this
schema/update.sql:-- optimizes individual player pages generation, since generating
schema/update.sql:-- all variants for all pages greatly increases the number of pages
schema/update.sql:-- generated, most of them being empty, since most players only play
schema/update.sql:-- one variant.
schema/update.sql:--
schema/update.sql:-- There are two classes of objects being tracked: variants (which
schema/update.sql:-- includes pseudovariant 'all') and names.
schema/update.sql:--
schema/update.sql:-- ('all'  , '')   -- combined stats need to be updated
schema/update.sql:-- (variant, '')   -- variant stats need to be update
schema/update.sql:-- ('all'  , name) -- all variants for player stats need to be updated
schema/update.sql:-- (variant, name) -- player/variant stats need to be updated
schema/update.sql:--
schema/update.sql:-- When nhdb-feeder detects, that this table has no rows in it, it will
schema/update.sql:-- initialize it with following two queries:
schema/update.sql:--
schema/update.sql:--    INSERT INTO update 
schema/update.sql:--    SELECT variant, name
schema/update.sql:--    FROM games LEFT JOIN logfiles USING (logfiles_i)
schema/update.sql:--    GROUP BY variant, name;
schema/update.sql:--    
schema/update.sql:--    INSERT INTO update 
schema/update.sql:--    SELECT 'all', name, FALSE
schema/update.sql:--    FROM games LEFT JOIN logfiles USING (logfiles_i)
schema/update.sql:--    GROUP BY name;
schema/update.sql:--
schema/update.sql:-- This initialization is critical for proper function of nhdb-stats!
schema/update.sql:-- Note, that currently this query takes over 100 seconds to complete.
schema/update.sql:--
schema/update.sql:-- This table only grows, no deletes are performed anywhere in the
schema/update.sql:-- nhdb. The only deletion necessary is when log source is removed
schema/update.sql:-- (from logfiles table); if that happens, this table should be completely
schema/update.sql:-- emptied by administrator;
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:--- clean-up
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:--- sequences
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:--- triggers
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:-- Following trigger function is bound to INSERT/DELETE on map_games_streaks
schema/streaks.sql:-- table that maps rows between "games" and "streaks" (N:1). It does two
schema/streaks.sql:-- things: 1) automatically increments/decrements streaks.num_games when
schema/streaks.sql:-- mapping is added/removed to/from map_games_streaks. 2) If
schema/streaks.sql:-- streaks.num_games reaches 0 on deleting; the streak itself is removed.
schema/streaks.sql:-- The latter functionality is here to make deleting games straightforward
schema/streaks.sql:-- but note that full consistency is still not guaranteed; if you delete
schema/streaks.sql:-- games from "games" table, you must delete all games with the same
schema/streaks.sql:-- logfiles_i to ensure integrity.
schema/streaks.sql:    UPDATE streaks SET num_games = num_games - 1 WHERE streaks_i = OLD.streaks_i 
schema/streaks.sql:-- streaks after-update trigger; if open is FALSE and num_games is 1, the
schema/streaks.sql:-- streak is deleted (closed streaks with length 1 are no streaks)
schema/streaks.sql:----------------------------------------------------------------------------
schema/streaks.sql:--- tables
schema/streaks.sql:----------------------------------------------------------------------------
schema/logfiles.sql:-- === logfiles table ===
schema/logfiles.sql:--
schema/logfiles.sql:-- logfiles_i
schema/logfiles.sql:-- Integer used to reference the logfiles entry; note that it is
schema/logfiles.sql:-- also referenced from nhdb configuration (nhdb-def.json)! Don't
schema/logfiles.sql:-- change this, preferably. Also, for /dev/null games, this id
schema/logfiles.sql:-- MUST be the year of the tournament. See function process_streaks()
schema/logfiles.sql:-- in nhdb-stats.pl.
schema/logfiles.sql:--
schema/logfiles.sql:-- descr
schema/logfiles.sql:-- Description of the entry; only shown on the About page
schema/logfiles.sql:--
schema/logfiles.sql:-- server
schema/logfiles.sql:-- Three letter server acronym in lowercase (such as "nao" for
schema/logfiles.sql:-- nethack.alt.org, "ade" for acehack.de etc.).
schema/logfiles.sql:--
schema/logfiles.sql:-- variant
schema/logfiles.sql:-- Variant acronym in lowercase (such as "nh" for vanilla NetHack,
schema/logfiles.sql:-- "ace" for AceHack, "nh4" for NetHack4 etc.)
schema/logfiles.sql:--
schema/logfiles.sql:-- version
schema/logfiles.sql:-- This is used as an additional distinguisher that can be acted upon
schema/logfiles.sql:-- (primarily by the feeder to modify its parsing behaviour).
schema/logfiles.sql:--
schema/logfiles.sql:-- logurl
schema/logfiles.sql:-- Fully qualified URL of xlogfile.
schema/logfiles.sql:--
schema/logfiles.sql:-- localfile
schema/logfiles.sql:-- Filename of a logfile on local filesystem.
schema/logfiles.sql:--
schema/logfiles.sql:-- dumpurl
schema/logfiles.sql:-- Determines location of the game dumps
schema/logfiles.sql:--
schema/logfiles.sql:-- rcfileurl
schema/logfiles.sql:-- Determines location of player rc files
schema/logfiles.sql:--
schema/logfiles.sql:-- options
schema/logfiles.sql:-- Defines options for the logfile, usually some special handling. Currently
schema/logfiles.sql:-- defined options are:
schema/logfiles.sql:--
schema/logfiles.sql:--  * bug360duration - do not show the duration to the user, this exists
schema/logfiles.sql:--      because NetHack 3.6.0 was recording bogus 'realtime' field into
schema/logfiles.sql:--      xlogfile
schema/logfiles.sql:--
schema/logfiles.sql:--  * base64xlog - this allows using base64 encoded data in xlogfile, the
schema/logfiles.sql:--      fields should have same name with '64' appended; if such encoded
schema/logfiles.sql:--      field exists, it is preferred to plain unencoded field
schema/logfiles.sql:--
schema/logfiles.sql:--  * devnull - this marks logfile as being from the /dev/null/nethack
schema/logfiles.sql:--      tournament, which means that it has slightly different format that
schema/logfiles.sql:--      needs to be accommodated
schema/logfiles.sql:-- 
schema/logfiles.sql:-- oper
schema/logfiles.sql:-- If true, the feeder will process this entry; if false the logfile
schema/logfiles.sql:-- will not be processed, essentially it won't exist for the feeder.
schema/logfiles.sql:-- This has no effect on games alread in the database and stats
schema/logfiles.sql:-- generator will still load all logfiles and process all games in db.
schema/logfiles.sql:-- Note, that if a full db reload is needed, oper must be set to true
schema/logfiles.sql:-- for the logfile to be reloaded! 
schema/logfiles.sql:--
schema/logfiles.sql:-- static
schema/logfiles.sql:-- If true, the feeder will not try to download the file from logurl,
schema/logfiles.sql:-- even if it is defined. This allows static logfiles to be part of the
schema/logfiles.sql:-- dataset (such as devnull logfiles, logfiles from discontinued sites etc.)
schema/logfiles.sql:-- In general, if you want to use static file, you probably also want 
schema/logfiles.sql:-- to set 'oper' to false.
schema/logfiles.sql:--
schema/logfiles.sql:-- tz
schema/logfiles.sql:-- Time zone used for this logfile
schema/logfiles.sql:--
schema/logfiles.sql:-- fpos
schema/logfiles.sql:-- Last file position; this is the file position the feeder will
schema/logfiles.sql:-- read the file from on the next run. After the feeder has run and
schema/logfiles.sql:-- processed the logfile, it is set to the log's filesize. By resetting
schema/logfiles.sql:-- this field, one forces the whole logfile to be parsed and fed into
schema/logfiles.sql:-- db again (but that won't erase the redundant db entries!)
schema/logfiles.sql:--
schema/logfiles.sql:-- lines
schema/logfiles.sql:-- Number of lines read so far. This is used to number the entries in the
schema/logfiles.sql:-- games table. This doesn't need to be the number of entries in the database,
schema/logfiles.sql:-- as some lines could possibly be rejected.
schema/logfiles.sql:--
schema/logfiles.sql:-- lastchk
schema/logfiles.sql:-- Time of last processing of the logfile.
schema/logfiles.sql:----------------------------------------------------------------------------
schema/logfiles.sql:--- views
schema/logfiles.sql:----------------------------------------------------------------------------
schema/logfiles.sql:    to_char(lastchk, 'YYYY-MM-DD HH24:MI') AS lastchk_trunc,
schema/logfiles.sql:    current_timestamp - lastchk < interval '1 hour' AS lastchk_1h,
schema/logfiles.sql:    current_timestamp - lastchk < interval '1 day' AS lastchk_1d,
schema/logfiles.sql:    current_timestamp - lastchk < interval '30 days' AS lastchk_30d,
schema/logfiles.sql:    to_char(max(endtime), 'YYYY-MM-DD HH24:MI') AS lastentry_trunc,
schema/logfiles.sql:    current_timestamp - max(endtime) < interval '1 hour' AS lastentry_1h,
schema/logfiles.sql:    current_timestamp - max(endtime) < interval '1 day' AS lastentry_1d,
schema/logfiles.sql:    current_timestamp - max(endtime) < interval '30 days' AS lastentry_30d
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- This file defines data sources NHS aggregates. Please note, that we define
schema/sources.sql:-- all sources with oper = TRUE, even historical sources with static = TRUE.
schema/sources.sql:-- The nhdb-feeder will read all operational sources in and if they are
schema/sources.sql:-- static, it will toggle the 'oper' field to false.
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- nethack.alt org/NAO ------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  79, 'nethack.alt.org (3.6.3-3.6.6)', 'nao', 'nh',
schema/sources.sql:  'nao.nh.363-6.log',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- acehack.de/ADE (defunct) -------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- eu.un.nethack.nu/UNE (defunct) -------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- Shut down in May 2018, archived on ascension.run
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- us.un.nethack.nu/UNU (defunct) -------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- Shut down in May 2018, archived on ascension.run
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- nethack4.org/N4O ---------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'n4o.nh4-3.log',
schema/sources.sql:-- Discontinued sometime in 2014, apparently no game dumps available
schema/sources.sql:  'http://nethack4.org/4.2-xlogfile',
schema/sources.sql:  'n4o.nh4-2.log',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- sporkhack.com/SHC (defunct) ----------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- Shut down in 2015, dump logs unavailable
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- grunthack.org/GHO --------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- dnethack.ilbelkyr.de/DID (defunct) ---------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- Shutdown in 2014, game dumps archived on ascension.run
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- acehack.eu/AEU (defunct) -------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- Shutdown in 2012, game dumps archived on ascension.run
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:--- ascension.run/ASC  ------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:--- Junethack 2015 SporkHack
schema/sources.sql:--- Junethack 2015 GruntHack
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:--- hardfought.org/HDF  -----------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'https://www.hardfought.org/xlogfiles/nethack/xlogfile-370-hdf',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- hardfought.org Europe/HFE ------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'https://eu.hardfought.org/xlogfiles/nethack/xlogfile-370-hdf',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- hardfought.org Australia/HFA ---------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'https://au.hardfought.org/xlogfiles/nethack/xlogfile-370-hdf',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- em.slashem.me/ESM --------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:--- xlogfile gratuitously discontinued on June 8, 2018
schema/sources.sql:--- xlogfile gratuitously discontinued on June 8, 2018
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- nethack.devnull.com/DEV --------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'devnull-2006.log',
schema/sources.sql:  'devnull-2007.log',
schema/sources.sql:  'devnull-2008.log',
schema/sources.sql:  'devnull-2009.log',
schema/sources.sql:  'devnull-2010.log',
schema/sources.sql:  'devnull-2011.log',
schema/sources.sql:  'devnull-2012.log',
schema/sources.sql:  'devnull-2013.log',
schema/sources.sql:  'devnull-2014.log',
schema/sources.sql:  'devnull-2015.log',
schema/sources.sql:  'devnull-2016.log',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- /dev/null/nethack Tribute 2017/DNT ---------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'devnull-2017.log',
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:-- TNNT ---------------------------------------------------------------------
schema/sources.sql:-----------------------------------------------------------------------------
schema/sources.sql:  'https://www.hardfought.org/xlogfiles/tnnt/xlogfile-tnnt-merged',
schema/sources.sql:  'tnnt-2018.log',
schema/sources.sql:  'tnnt-2019.log',
